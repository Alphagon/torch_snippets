[
  {
    "objectID": "imgaug_loader.html",
    "href": "imgaug_loader.html",
    "title": "Imgaug",
    "section": "",
    "text": "wrappers for common imgaug functions, that accept image and ocr data frame of bounding boxes\n\n\nfrom torch_snippets.loader import read, pd, show\n\nIM = read(\"/Users/yeshwanth.y/code/torch_snippets/assets/Preamble.png\")\nDF = pd.read_csv(\"/Users/yeshwanth.y/code/torch_snippets/assets/Preamble.csv\")\nDF = to_relative(DF, *IM.shape[:2])\nDF.head()\n\n\n\n\n\n\n\n\nx\ny\nX\nY\ntext\nblock_id\n\n\n\n\n0\n0.249538\n0.253501\n0.569316\n0.305322\nConstITUtIO\n0\n\n\n1\n0.288355\n0.369748\n0.401109\n0.397759\nNLTHE\n1\n\n\n2\n0.402957\n0.369748\n0.510166\n0.397759\nPEOPLE\n1\n\n\n3\n0.493530\n0.371148\n0.545287\n0.394958\nOF\n1\n\n\n4\n0.548983\n0.369748\n0.630314\n0.397759\nINDIA,\n1\n\n\n\n\n\n\n\n\n\n\nim = IM.copy()\nim = rescale(im, sz=(400, 600))\nshow(im, sz=5)\n\n\n\n\n\n\n\n\n\ndf = DF.copy()\nim = IM.copy()\nim, df = rescale(im, df, (400, 600))\nshow(im, df=df, sz=5)\ndf.head()\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb Cell 8 in &lt;cell line: 3&gt;()\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=0'&gt;1&lt;/a&gt; df = DF.copy()\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=1'&gt;2&lt;/a&gt; im = IM.copy()\n----&gt; &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=2'&gt;3&lt;/a&gt; im, df = rescale(im, df, (400, 600))\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=3'&gt;4&lt;/a&gt; show(im, df=df, sz=5)\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=4'&gt;5&lt;/a&gt; df.head()\n\n/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb Cell 8 in rescale(im, bbs, sz)\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=110'&gt;111&lt;/a&gt; H, W = get_size(sz, h, w)\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=111'&gt;112&lt;/a&gt; aug = iaa.Resize({\"height\": H, \"width\": W})\n--&gt; &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=112'&gt;113&lt;/a&gt; im, bbs = do(im, bbs, aug)\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=113'&gt;114&lt;/a&gt; if to_pil:\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=114'&gt;115&lt;/a&gt;     im = PIL.Image.fromarray(im)\n\n/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb Cell 8 in do(img, bbs, aug, cval)\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=41'&gt;42&lt;/a&gt;         __df = combine_xyXY_to_bb(__df)\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=42'&gt;43&lt;/a&gt;     bbs = __df\n---&gt; &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=43'&gt;44&lt;/a&gt; if bbs == []:\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=44'&gt;45&lt;/a&gt;     return img, []\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=45'&gt;46&lt;/a&gt; return img, bbs\n\nFile ~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/__init__.py:705, in _comp_method_FRAME.&lt;locals&gt;.f(self, other)\n    701 @Appender(f\"Wrapper for comparison method {op_name}\")\n    702 def f(self, other):\n    703     axis = 1  # only relevant for Series other case\n--&gt; 705     self, other = _align_method_FRAME(self, other, axis, level=None, flex=False)\n    707     # See GH#4537 for discussion of scalar op behavior\n    708     new_data = dispatch_to_series(self, other, op, axis=axis)\n\nFile ~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/__init__.py:503, in _align_method_FRAME(left, right, axis, flex, level)\n    496         raise ValueError(\n    497             \"Unable to coerce to Series/DataFrame, \"\n    498             f\"dimension must be &lt;= 2: {right.shape}\"\n    499         )\n    501 elif is_list_like(right) and not isinstance(right, (ABCSeries, ABCDataFrame)):\n    502     # GH17901\n--&gt; 503     right = to_series(right)\n    505 if flex is not None and isinstance(right, ABCDataFrame):\n    506     if not left._indexed_same(right):\n\nFile ~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/__init__.py:465, in _align_method_FRAME.&lt;locals&gt;.to_series(right)\n    463 else:\n    464     if len(left.columns) != len(right):\n--&gt; 465         raise ValueError(\n    466             msg.format(req_len=len(left.columns), given_len=len(right))\n    467         )\n    468     right = left._constructor_sliced(right, index=left.columns)\n    469 return right\n\nValueError: Unable to coerce to Series, length must be 6: given 0\n\n\n\n\n\n\n\nfor i in range(11):\n    angle = (i - 5) * 5\n    print(angle)\n    im = rotate(IM, angle=angle)\n    show(im, sz=1)\n\n-25\n\n\n\n\n\n\n\n\n\n-20\n\n\n\n\n\n\n\n\n\n-15\n\n\n\n\n\n\n\n\n\n-10\n\n\n\n\n\n\n\n\n\n-5\n\n\n\n\n\n\n\n\n\n0\n\n\n\n\n\n\n\n\n\n5\n\n\n\n\n\n\n\n\n\n10\n\n\n\n\n\n\n\n\n\n15\n\n\n\n\n\n\n\n\n\n20\n\n\n\n\n\n\n\n\n\n25\n\n\n\n\n\n\n\n\n\n\ndf = DF.copy()\nim = IM.copy()\nim, df = rotate(im, df, 90)\nshow(im, df=df, sz=20)\nprint(type(im))\ndf.head()\n\n\n\n\n\n\n\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\n\n\n\n\n\n\ntext\nblock_id\nx\ny\nX\nY\n\n\n\n\n0\nConstITUtIO\n0\n0.693277\n0.249538\n0.745098\n0.569316\n\n\n1\nNLTHE\n1\n0.600840\n0.288355\n0.628852\n0.401109\n\n\n2\nPEOPLE\n1\n0.600840\n0.402957\n0.628852\n0.510166\n\n\n3\nOF\n1\n0.603641\n0.493530\n0.627451\n0.545287\n\n\n4\nINDIA,\n1\n0.600840\n0.548983\n0.628852\n0.630314\n\n\n\n\n\n\n\n\n\n\n\ndf = DF.copy()\nim = IM.copy()\nim, df = pad(im, df, deltas=(90, 90), cval=0)\nshow(im, df=df, sz=20)\nprint(type(im))\ndf.head()\n\n\n\n\n\n\n\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\n\n\n\n\n\n\ntext\nblock_id\nx\ny\nX\nY\n\n\n\n\n0\nConstITUtIO\n0\n0.310536\n0.302521\n0.550832\n0.343137\n\n\n1\nNLTHE\n1\n0.340111\n0.394958\n0.425139\n0.417367\n\n\n2\nPEOPLE\n1\n0.426987\n0.394958\n0.506470\n0.417367\n\n\n3\nOF\n1\n0.493530\n0.396359\n0.532348\n0.415966\n\n\n4\nINDIA,\n1\n0.536044\n0.394958\n0.597043\n0.417367\n\n\n\n\n\n\n\n\n\n\nAll functions will work with data frames that contain either of absolute/relative coordinates, and will preserve the image type (np.ndarray or PIL.Image.Image) too\n\ndf = DF.copy()\nim = IM.copy()\nheight, width = im.shape\nshow(df.head())\nim = PIL.Image.fromarray(im)\nim, df = rotate(im, df, 45, cval=127)\nim, df = pad(im, df, deltas=(200, 200), cval=0)\nim, df = rescale(im, df, sz=(300, 300))\nshow(im, df=df, sz=20)\nprint(type(im))\ndf.head()\n\n\n\n\n\n\n\n\nx\ny\nX\nY\ntext\nblock_id\n\n\n\n\n0\n0.249538\n0.253501\n0.569316\n0.305322\nConstITUtIO\n0\n\n\n1\n0.288355\n0.369748\n0.401109\n0.397759\nNLTHE\n1\n\n\n2\n0.402957\n0.369748\n0.510166\n0.397759\nPEOPLE\n1\n\n\n3\n0.493530\n0.371148\n0.545287\n0.394958\nOF\n1\n\n\n4\n0.548983\n0.369748\n0.630314\n0.397759\nINDIA,\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;class 'PIL.Image.Image'&gt;\n\n\n\n\n\n\n\n\n\ntext\nblock_id\nx\ny\nX\nY\n\n\n\n\n0\nConstITUtIO\n0\n0.500000\n0.326667\n0.613333\n0.440000\n\n\n1\nNLTHE\n1\n0.473333\n0.383333\n0.516667\n0.426667\n\n\n2\nPEOPLE\n1\n0.506667\n0.416667\n0.550000\n0.460000\n\n\n3\nOF\n1\n0.536667\n0.446667\n0.560000\n0.470000\n\n\n4\nINDIA,\n1\n0.550000\n0.460000\n0.586667\n0.493333",
    "crumbs": [
      "Imgaug"
    ]
  },
  {
    "objectID": "imgaug_loader.html#rescale",
    "href": "imgaug_loader.html#rescale",
    "title": "Imgaug",
    "section": "",
    "text": "im = IM.copy()\nim = rescale(im, sz=(400, 600))\nshow(im, sz=5)\n\n\n\n\n\n\n\n\n\ndf = DF.copy()\nim = IM.copy()\nim, df = rescale(im, df, (400, 600))\nshow(im, df=df, sz=5)\ndf.head()\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb Cell 8 in &lt;cell line: 3&gt;()\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=0'&gt;1&lt;/a&gt; df = DF.copy()\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=1'&gt;2&lt;/a&gt; im = IM.copy()\n----&gt; &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=2'&gt;3&lt;/a&gt; im, df = rescale(im, df, (400, 600))\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=3'&gt;4&lt;/a&gt; show(im, df=df, sz=5)\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=4'&gt;5&lt;/a&gt; df.head()\n\n/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb Cell 8 in rescale(im, bbs, sz)\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=110'&gt;111&lt;/a&gt; H, W = get_size(sz, h, w)\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=111'&gt;112&lt;/a&gt; aug = iaa.Resize({\"height\": H, \"width\": W})\n--&gt; &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=112'&gt;113&lt;/a&gt; im, bbs = do(im, bbs, aug)\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=113'&gt;114&lt;/a&gt; if to_pil:\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=114'&gt;115&lt;/a&gt;     im = PIL.Image.fromarray(im)\n\n/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb Cell 8 in do(img, bbs, aug, cval)\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=41'&gt;42&lt;/a&gt;         __df = combine_xyXY_to_bb(__df)\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=42'&gt;43&lt;/a&gt;     bbs = __df\n---&gt; &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=43'&gt;44&lt;/a&gt; if bbs == []:\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=44'&gt;45&lt;/a&gt;     return img, []\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=45'&gt;46&lt;/a&gt; return img, bbs\n\nFile ~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/__init__.py:705, in _comp_method_FRAME.&lt;locals&gt;.f(self, other)\n    701 @Appender(f\"Wrapper for comparison method {op_name}\")\n    702 def f(self, other):\n    703     axis = 1  # only relevant for Series other case\n--&gt; 705     self, other = _align_method_FRAME(self, other, axis, level=None, flex=False)\n    707     # See GH#4537 for discussion of scalar op behavior\n    708     new_data = dispatch_to_series(self, other, op, axis=axis)\n\nFile ~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/__init__.py:503, in _align_method_FRAME(left, right, axis, flex, level)\n    496         raise ValueError(\n    497             \"Unable to coerce to Series/DataFrame, \"\n    498             f\"dimension must be &lt;= 2: {right.shape}\"\n    499         )\n    501 elif is_list_like(right) and not isinstance(right, (ABCSeries, ABCDataFrame)):\n    502     # GH17901\n--&gt; 503     right = to_series(right)\n    505 if flex is not None and isinstance(right, ABCDataFrame):\n    506     if not left._indexed_same(right):\n\nFile ~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/__init__.py:465, in _align_method_FRAME.&lt;locals&gt;.to_series(right)\n    463 else:\n    464     if len(left.columns) != len(right):\n--&gt; 465         raise ValueError(\n    466             msg.format(req_len=len(left.columns), given_len=len(right))\n    467         )\n    468     right = left._constructor_sliced(right, index=left.columns)\n    469 return right\n\nValueError: Unable to coerce to Series, length must be 6: given 0",
    "crumbs": [
      "Imgaug"
    ]
  },
  {
    "objectID": "imgaug_loader.html#rotate",
    "href": "imgaug_loader.html#rotate",
    "title": "Imgaug",
    "section": "",
    "text": "for i in range(11):\n    angle = (i - 5) * 5\n    print(angle)\n    im = rotate(IM, angle=angle)\n    show(im, sz=1)\n\n-25\n\n\n\n\n\n\n\n\n\n-20\n\n\n\n\n\n\n\n\n\n-15\n\n\n\n\n\n\n\n\n\n-10\n\n\n\n\n\n\n\n\n\n-5\n\n\n\n\n\n\n\n\n\n0\n\n\n\n\n\n\n\n\n\n5\n\n\n\n\n\n\n\n\n\n10\n\n\n\n\n\n\n\n\n\n15\n\n\n\n\n\n\n\n\n\n20\n\n\n\n\n\n\n\n\n\n25\n\n\n\n\n\n\n\n\n\n\ndf = DF.copy()\nim = IM.copy()\nim, df = rotate(im, df, 90)\nshow(im, df=df, sz=20)\nprint(type(im))\ndf.head()\n\n\n\n\n\n\n\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\n\n\n\n\n\n\ntext\nblock_id\nx\ny\nX\nY\n\n\n\n\n0\nConstITUtIO\n0\n0.693277\n0.249538\n0.745098\n0.569316\n\n\n1\nNLTHE\n1\n0.600840\n0.288355\n0.628852\n0.401109\n\n\n2\nPEOPLE\n1\n0.600840\n0.402957\n0.628852\n0.510166\n\n\n3\nOF\n1\n0.603641\n0.493530\n0.627451\n0.545287\n\n\n4\nINDIA,\n1\n0.600840\n0.548983\n0.628852\n0.630314",
    "crumbs": [
      "Imgaug"
    ]
  },
  {
    "objectID": "imgaug_loader.html#pad",
    "href": "imgaug_loader.html#pad",
    "title": "Imgaug",
    "section": "",
    "text": "df = DF.copy()\nim = IM.copy()\nim, df = pad(im, df, deltas=(90, 90), cval=0)\nshow(im, df=df, sz=20)\nprint(type(im))\ndf.head()\n\n\n\n\n\n\n\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\n\n\n\n\n\n\ntext\nblock_id\nx\ny\nX\nY\n\n\n\n\n0\nConstITUtIO\n0\n0.310536\n0.302521\n0.550832\n0.343137\n\n\n1\nNLTHE\n1\n0.340111\n0.394958\n0.425139\n0.417367\n\n\n2\nPEOPLE\n1\n0.426987\n0.394958\n0.506470\n0.417367\n\n\n3\nOF\n1\n0.493530\n0.396359\n0.532348\n0.415966\n\n\n4\nINDIA,\n1\n0.536044\n0.394958\n0.597043\n0.417367",
    "crumbs": [
      "Imgaug"
    ]
  },
  {
    "objectID": "imgaug_loader.html#augmentations-as-monads",
    "href": "imgaug_loader.html#augmentations-as-monads",
    "title": "Imgaug",
    "section": "",
    "text": "All functions will work with data frames that contain either of absolute/relative coordinates, and will preserve the image type (np.ndarray or PIL.Image.Image) too\n\ndf = DF.copy()\nim = IM.copy()\nheight, width = im.shape\nshow(df.head())\nim = PIL.Image.fromarray(im)\nim, df = rotate(im, df, 45, cval=127)\nim, df = pad(im, df, deltas=(200, 200), cval=0)\nim, df = rescale(im, df, sz=(300, 300))\nshow(im, df=df, sz=20)\nprint(type(im))\ndf.head()\n\n\n\n\n\n\n\n\nx\ny\nX\nY\ntext\nblock_id\n\n\n\n\n0\n0.249538\n0.253501\n0.569316\n0.305322\nConstITUtIO\n0\n\n\n1\n0.288355\n0.369748\n0.401109\n0.397759\nNLTHE\n1\n\n\n2\n0.402957\n0.369748\n0.510166\n0.397759\nPEOPLE\n1\n\n\n3\n0.493530\n0.371148\n0.545287\n0.394958\nOF\n1\n\n\n4\n0.548983\n0.369748\n0.630314\n0.397759\nINDIA,\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;class 'PIL.Image.Image'&gt;\n\n\n\n\n\n\n\n\n\ntext\nblock_id\nx\ny\nX\nY\n\n\n\n\n0\nConstITUtIO\n0\n0.500000\n0.326667\n0.613333\n0.440000\n\n\n1\nNLTHE\n1\n0.473333\n0.383333\n0.516667\n0.426667\n\n\n2\nPEOPLE\n1\n0.506667\n0.416667\n0.550000\n0.460000\n\n\n3\nOF\n1\n0.536667\n0.446667\n0.560000\n0.470000\n\n\n4\nINDIA,\n1\n0.550000\n0.460000\n0.586667\n0.493333",
    "crumbs": [
      "Imgaug"
    ]
  },
  {
    "objectID": "bokeh_plotting.html",
    "href": "bokeh_plotting.html",
    "title": "Bokeh Plots",
    "section": "",
    "text": "bplot = get_bplot()\nbplot.line(np.arange(100), np.cumsum(np.random.uniform(size=100)))\nbshow(bplot)",
    "crumbs": [
      "Bokeh Plots"
    ]
  },
  {
    "objectID": "logging.html",
    "href": "logging.html",
    "title": "Rich Logging and printing",
    "section": "",
    "text": "print(\"The Number is 128\")\nprint(\n    {\n        \"a\": 1,\n        \"b\": [\n            {1, 2, 3},\n            \"lskjdf\",\n        ],\n        \"c\": 1,\n        \"d\": [\n            {1, 2, 3},\n            \"lskjdf\",\n        ],\n        \"ae\": 1,\n        \"bf\": [\n            {1, 2, 3},\n            \"lskjdf\",\n        ],\n        \"ag\": 1,\n        \"ba\": [\n            {1, 2, 3},\n            \"lskjdf\",\n        ],\n    }\n)\n\nThe Number is 128\n\n\n\n{\n    'a': 1,\n    'b': [{1, 2, 3}, 'lskjdf'],\n    'c': 1,\n    'd': [{1, 2, 3}, 'lskjdf'],\n    'ae': 1,\n    'bf': [{1, 2, 3}, 'lskjdf'],\n    'ag': 1,\n    'ba': [{1, 2, 3}, 'lskjdf']\n}\n\n\n\n\nprint(r\"\\x86\")\n\n\\x86\n\n\n\n\na = {1: 1221, 2: 2342}\ndel a[1]\na\n\n{2: 2342}\n\n\n\nDebug(\"TESTING {1,2,3}\")\nInfo(\"TESTING {1,2,3}\")\nWarn(\"TESTING {1,2,3}\")\nExcep(\"TESTING {1,2,3}\")\n\n[09/22/23 17:40:13] INFO     TESTING {1,2,3}                                                                                                        3592958886.py:&lt;module&gt;:2\n\n\n\n                    WARNING  TESTING {1,2,3}                                                                                                        3592958886.py:&lt;module&gt;:3\n\n\n\n                    ERROR    TESTING {1,2,3}                                                                                                        3592958886.py:&lt;module&gt;:4\n\n\n\n\n\nenter_exit\n\n enter_exit (func)\n\nLogs the time taken to execute a function along with entry & exit time stamps\n\n@enter_exit\ndef add(x, y):\n    print(\"sleeping...\")\n    time.sleep(2)\n    return x + y\n\n\nadd(1, 23)\n\nsleeping...\n\n\n\n24\n\n\n\ndef do():\n    try:\n        1 / 0\n    except Exception as e:\n        # console.print_exception(max_frames=20)\n        logger.exception(e)\n\n\ndef do2():\n    do()\n\n\ndo2()\n\n[09/22/23 17:40:15] ERROR    division by zero                                                                                                             1990218183.py:do:6\n                             Traceback (most recent call last):                                                                                                             \n                                                                                                                                                                            \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/runpy.py\", line 194, in _run_module_as_main                                       \n                                 return _run_code(code, main_globals, None,                                                                                                 \n                                        |         |     -&gt; {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nThis is                     \n                             separate from the ipykernel pack...                                                                                                            \n                                        |         -&gt; &lt;code object &lt;module&gt; at 0x7f7f004adbe0, file                                                                          \n                             \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/ipykernel_l...                                                             \n                                        -&gt; &lt;function _run_code at 0x7f7f004baaf0&gt;                                                                                           \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/runpy.py\", line 87, in _run_code                                                  \n                                 exec(code, run_globals)                                                                                                                    \n                                      |     -&gt; {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nThis is separate from                   \n                             the ipykernel pack...                                                                                                                          \n                                      -&gt; &lt;code object &lt;module&gt; at 0x7f7f004adbe0, file                                                                                      \n                             \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/ipykernel_l...                                                             \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in &lt;module&gt;                        \n                                 app.launch_new_instance()                                                                                                                  \n                                 |   -&gt; &lt;bound method Application.launch_instance of &lt;class 'ipykernel.kernelapp.IPKernelApp'&gt;&gt;                                             \n                                 -&gt; &lt;module 'ipykernel.kernelapp' from                                                                                                      \n                             '/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/ipykernel/kernelapp.py'&gt;                                                   \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in                      \n                             launch_instance                                                                                                                                \n                                 app.start()                                                                                                                                \n                                 |   -&gt; &lt;function IPKernelApp.start at 0x7f7f040989d0&gt;                                                                                      \n                                 -&gt; &lt;ipykernel.kernelapp.IPKernelApp object at 0x7f7efce6a970&gt;                                                                              \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start                         \n                                 self.io_loop.start()                                                                                                                       \n                                 |    |       -&gt; &lt;function BaseAsyncIOLoop.start at 0x7f7f024d7280&gt;                                                                         \n                                 |    -&gt; &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f7f04121550&gt;                                                                \n                                 -&gt; &lt;ipykernel.kernelapp.IPKernelApp object at 0x7f7efce6a970&gt;                                                                              \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start                    \n                                 self.asyncio_loop.run_forever()                                                                                                            \n                                 |    |            -&gt; &lt;function BaseEventLoop.run_forever at 0x7f7f021611f0&gt;                                                                \n                                 |    -&gt; &lt;_UnixSelectorEventLoop running=True closed=False debug=False&gt;                                                                     \n                                 -&gt; &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f7f04121550&gt;                                                                     \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever                                 \n                                 self._run_once()                                                                                                                           \n                                 |    -&gt; &lt;function BaseEventLoop._run_once at 0x7f7f02162d30&gt;                                                                               \n                                 -&gt; &lt;_UnixSelectorEventLoop running=True closed=False debug=False&gt;                                                                          \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once                                  \n                                 handle._run()                                                                                                                              \n                                 |      -&gt; &lt;function Handle._run at 0x7f7f02103a60&gt;                                                                                         \n                                 -&gt; &lt;Handle &lt;TaskWakeupMethWrapper object at 0x7f7f0465e040&gt;(&lt;Future finis...7d0&gt;, ...],))&gt;)&gt;                                               \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/asyncio/events.py\", line 81, in _run                                              \n                                 self._context.run(self._callback, *self._args)                                                                                             \n                                 |    |            |    |           |    -&gt; &lt;member '_args' of 'Handle' objects&gt;                                                            \n                                 |    |            |    |           -&gt; &lt;Handle &lt;TaskWakeupMethWrapper object at 0x7f7f0465e040&gt;(&lt;Future finis...7d0&gt;,                       \n                             ...],))&gt;)&gt;                                                                                                                                     \n                                 |    |            |    -&gt; &lt;member '_callback' of 'Handle' objects&gt;                                                                         \n                                 |    |            -&gt; &lt;Handle &lt;TaskWakeupMethWrapper object at 0x7f7f0465e040&gt;(&lt;Future finis...7d0&gt;, ...],))&gt;)&gt;                             \n                                 |    -&gt; &lt;member '_context' of 'Handle' objects&gt;                                                                                            \n                                 -&gt; &lt;Handle &lt;TaskWakeupMethWrapper object at 0x7f7f0465e040&gt;(&lt;Future finis...7d0&gt;, ...],))&gt;)&gt;                                               \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in                              \n                             dispatch_queue                                                                                                                                 \n                                 await self.process_one()                                                                                                                   \n                                       |    -&gt; &lt;function Kernel.process_one at 0x7f7f036bb670&gt;                                                                              \n                                       -&gt; &lt;ipykernel.ipkernel.IPythonKernel object at 0x7f7f04093f10&gt;                                                                       \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in                              \n                             process_one                                                                                                                                    \n                                 await dispatch(*args)                                                                                                                      \n                                       |         -&gt; ([&lt;zmq.sugar.frame.Frame object at 0x7f7f04623510&gt;, &lt;zmq.sugar.frame.Frame object at 0x7f7f046231a0&gt;,                   \n                             &lt;zmq.sugar.frame.Frame ...                                                                                                                     \n                                       -&gt; &lt;bound method Kernel.dispatch_shell of &lt;ipykernel.ipkernel.IPythonKernel object at 0x7f7f04093f10&gt;&gt;                               \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in                              \n                             dispatch_shell                                                                                                                                 \n                                 await result                                                                                                                               \n                                       -&gt; &lt;coroutine object Kernel.execute_request at 0x7f7f04cddd40&gt;                                                                       \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in                              \n                             execute_request                                                                                                                                \n                                 reply_content = await reply_content                                                                                                        \n                                                       -&gt; &lt;coroutine object IPythonKernel.do_execute at 0x7f7f046223c0&gt;                                                     \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute                     \n                                 res = shell.run_cell(                                                                                                                      \n                                       |     -&gt; &lt;function ZMQInteractiveShell.run_cell at 0x7f7f0408c1f0&gt;                                                                   \n                                       -&gt; &lt;ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f7f04121af0&gt;                                                                 \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell                       \n                                 return super().run_cell(*args, **kwargs)                                                                                                   \n                                                          |       -&gt; {'store_history': True, 'silent': False, 'cell_id':                                                    \n                             'vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/logging....                                                                   \n                                                          -&gt; ('def do():\\n    try:\\n        1 / 0\\n    except Exception as e:\\n        #                                    \n                             console.print_exception(max_frames=20)\\n        l...                                                                                           \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in                    \n                             run_cell                                                                                                                                       \n                                 result = self._run_cell(                                                                                                                   \n                                          |    -&gt; &lt;function InteractiveShell._run_cell at 0x7f7f02bec0d0&gt;                                                                   \n                                          -&gt; &lt;ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f7f04121af0&gt;                                                              \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2995, in                    \n                             _run_cell                                                                                                                                      \n                                 return runner(coro)                                                                                                                        \n                                        |      -&gt; &lt;coroutine object InteractiveShell.run_cell_async at 0x7f7f04d3a5c0&gt;                                                      \n                                        -&gt; &lt;function _pseudo_sync_runner at 0x7f7f02bdb9d0&gt;                                                                                 \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in                        \n                             _pseudo_sync_runner                                                                                                                            \n                                 coro.send(None)                                                                                                                            \n                                 |    -&gt; &lt;method 'send' of 'coroutine' objects&gt;                                                                                             \n                                 -&gt; &lt;coroutine object InteractiveShell.run_cell_async at 0x7f7f04d3a5c0&gt;                                                                    \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3194, in                    \n                             run_cell_async                                                                                                                                 \n                                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,                                                                            \n                                                    |    |             |        |     -&gt;                                                                                    \n                             '/var/folders/cp/1fbgq2n922j8ztdsq6551vldkr5sdy/T/ipykernel_15575/1990218183.py'                                                               \n                                                    |    |             |        -&gt; [&lt;_ast.FunctionDef object at 0x7f7f04cd5d90&gt;, &lt;_ast.FunctionDef object                   \n                             at 0x7f7f047188e0&gt;, &lt;_ast.Expr object at 0x7f7f047185b0&gt;]                                                                                      \n                                                    |    |             -&gt; &lt;_ast.Module object at 0x7f7f04cd5eb0&gt;                                                            \n                                                    |    -&gt; &lt;function InteractiveShell.run_ast_nodes at 0x7f7f02bec3a0&gt;                                                     \n                                                    -&gt; &lt;ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f7f04121af0&gt;                                                    \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3373, in                    \n                             run_ast_nodes                                                                                                                                  \n                                 if await self.run_code(code, result, async_=asy):                                                                                          \n                                          |    |        |     |              -&gt; False                                                                                       \n                                          |    |        |     -&gt; &lt;ExecutionResult object at 7f7f04718640, execution_count=11 error_before_exec=None                         \n                             error_in_exec=None info=&lt;ExecutionInfo obj...                                                                                                  \n                                          |    |        -&gt; &lt;code object &lt;module&gt; at 0x7f7f04d1b920, file                                                                    \n                             \"/var/folders/cp/1fbgq2n922j8ztdsq6551vldkr5sdy/T/ipykernel_15575/1990218183.py...                                                             \n                                          |    -&gt; &lt;function InteractiveShell.run_code at 0x7f7f02bec430&gt;                                                                    \n                                          -&gt; &lt;ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f7f04121af0&gt;                                                              \n                               File \"/Users/yeshwanth.y/miniconda3/envs/mdm/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3433, in                    \n                             run_code                                                                                                                                       \n                                 exec(code_obj, self.user_global_ns, self.user_ns)                                                                                          \n                                      |         |    |               |    -&gt; {'__name__': '__main__', '__doc__': 'Automatically created module for                          \n                             IPython interactive environment', '__package__': None, ...                                                                                     \n                                      |         |    |               -&gt; &lt;ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f7f04121af0&gt;                                   \n                                      |         |    -&gt; &lt;property object at 0x7f7f02bde810&gt;                                                                                 \n                                      |         -&gt; &lt;ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f7f04121af0&gt;                                                        \n                                      -&gt; &lt;code object &lt;module&gt; at 0x7f7f04d1b920, file                                                                                      \n                             \"/var/folders/cp/1fbgq2n922j8ztdsq6551vldkr5sdy/T/ipykernel_15575/1990218183.py...                                                             \n                                                                                                                                                                            \n                               File \"/var/folders/cp/1fbgq2n922j8ztdsq6551vldkr5sdy/T/ipykernel_15575/1990218183.py\", line 13, in &lt;module&gt;                                  \n                                 do2()                                                                                                                                      \n                                 -&gt; &lt;function do2 at 0x7f7f04d48ca0&gt;                                                                                                        \n                                                                                                                                                                            \n                               File \"/var/folders/cp/1fbgq2n922j8ztdsq6551vldkr5sdy/T/ipykernel_15575/1990218183.py\", line 10, in do2                                       \n                                 do()                                                                                                                                       \n                                 -&gt; &lt;function do at 0x7f7f04d48d30&gt;                                                                                                         \n                                                                                                                                                                            \n                             &gt; File \"/var/folders/cp/1fbgq2n922j8ztdsq6551vldkr5sdy/T/ipykernel_15575/1990218183.py\", line 3, in do                                         \n                                 1 / 0                                                                                                                                      \n                                                                                                                                                                            \n                             ZeroDivisionError: division by zero                                                                                                            \n                                                                                                                                                                            \n                             ╭─────────────────────────────────────────── Traceback (most recent call last) ────────────────────────────────────────────╮                   \n                             │ /var/folders/cp/1fbgq2n922j8ztdsq6551vldkr5sdy/T/ipykernel_15575/1990218183.py:3 in do                                   │                   \n                             │                                                                                                                          │                   \n                             │ [Errno 2] No such file or directory: '/var/folders/cp/1fbgq2n922j8ztdsq6551vldkr5sdy/T/ipykernel_15575/1990218183.py'    │                   \n                             ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯                   \n                             ZeroDivisionError: division by zero                                                                                                            \n\n\n\n\n\n\nin_logger_mode\n\n in_logger_mode (level)\n\n\n\n\nlogger_mode\n\n logger_mode (level)\n\n\n\n\nget_logger_level\n\n get_logger_level ()\n\n\ndef do():\n    Debug(1)\n    Info(2)\n    Warn(3)\n    Excep(4)\n\n\ndef line(x):\n    sep = \"=\" * 20\n    print(f\"{sep}{x}{sep}\")\n    print(f\"{in_excep_mode()=}\")\n    print(f\"{in_warn_mode()=}\")\n    print(f\"{in_info_mode()=}\")\n    print(f\"{in_debug_mode()=}\")\n\n\nreset_logger()\n\nwith excep_mode():\n    line(\"Excep mode\")\n    do()\n\nwith warn_mode():\n    line(\"Warn mode\")\n    do()\n\nwith info_mode():\n    line(\"Info mode\")\n    do()\n\nwith debug_mode():\n    line(\"Debug mode\")\n    do()\n\n\nreset_logger(\"debug\")\nprint(in_debug_mode())\nreset_logger()\nprint(in_debug_mode())\nwith debug_mode():\n    print(in_debug_mode())\nprint(in_debug_mode())\n\nTrue\n\n\n\nFalse\n\n\n\nTrue\n\n\n\nFalse\n\n\n\n\n\n\nnotify_waiting\n\n notify_waiting (message)",
    "crumbs": [
      "Rich Logging and printing"
    ]
  },
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Report",
    "section": "",
    "text": "Report\n\n\nfrom torch_snippets.torch_loader import Report\nimport numpy as np\nimport time\n\n\nn_epochs = 3\nreport = Report(n_epochs)\nrandom_walker1 = 0\nrandom_walker2 = 0\n\nfor epoch in range(n_epochs):\n    for ix in range(1000):\n        report.record(\n            pos=epoch + (ix + 1) / 1000,\n            loss=random_walker1,\n            val_loss=random_walker2,\n            end=\"\\r\",\n        )\n        random_walker1 += np.random.normal()\n        random_walker2 += np.random.normal()\n        time.sleep(0.001)\n    report.report_avgs(epoch + 1)\n\nreport.plot()\n\nEPOCH: 1.000    loss: -6.503    val_loss: -3.093    (1.19s - 2.38s remaining)))\nEPOCH: 2.000    loss: 48.754    val_loss: -6.265    (2.37s - 1.18s remaining))\nEPOCH: 3.000    loss: 38.115    val_loss: -29.732   (3.54s - 0.00s remaining)\n\n\n\n\n\n\n\n\n\n\nn_epochs = 5\nreport = Report(n_epochs, old_report=report)\n\nfor epoch in range(n_epochs):\n    for ix in range(1000):\n        report.record(\n            pos=epoch + (ix + 1) / 1000,\n            loss=random_walker1,\n            val_loss=random_walker2,\n            end=\"\\r\",\n        )\n        random_walker1 += np.random.normal()\n        random_walker2 += np.random.normal()\n        time.sleep(0.001)\n    report.report_avgs(epoch + 1)\n\nEPOCH: 1.000    loss: 29.338    val_loss: -74.955   (1.17s - 4.70s remaining))\nEPOCH: 2.000    loss: 0.340 val_loss: -110.763  (2.35s - 3.52s remaining)))\nEPOCH: 3.000    loss: 30.617    val_loss: -84.599   (3.51s - 2.34s remaining))\nEPOCH: 4.000    loss: 34.309    val_loss: -27.520   (4.68s - 1.17s remaining)\nEPOCH: 5.000    loss: 15.252    val_loss: -46.033   (5.85s - 0.00s remaining)\n\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nax.vlines(0, -100, 100, colors=[\"red\"])\nreport.plot(ax=ax)",
    "crumbs": [
      "Report"
    ]
  },
  {
    "objectID": "registry.html",
    "href": "registry.html",
    "title": "Registry",
    "section": "",
    "text": "Suppose you have a file called config.ini like so…\n\n!cat /tmp/config.ini\n\n\n[META]\nversion = 0.0.1\nname = mnist\nroot = /home/me/projects/${META.name}\ndescription = This is a sample\n    config file with a multiline\n    description. These are useful for\n    project descriptions/changelog/devnotes etc...\n\n[Data]\nsource = https://files.fast.ai/data/examples/mnist_tiny.tgz\nroot = ${META.root}/data/\n\n[misc]\nx = 1\ny = 20\nz = float(${x}*${y}**2)\na = ['hello','hi','how','are','you', ${x}*${z}*${y}]\nb = {\"hi\": 1, \"hello\": 2}\n\n[load]\n    [load.test]\n    @load = print_root_location\n    root = ${Data.root}\n    \n    [load.csv]\n    @load = load_csv_function\n    root = ${Data.root}\n    \n    [load.json]\n    @load = load_json_class\n    root = ${Data.root}\n    \n    \n\n\n\nYou can load it up as an AttrDict\n\nconfig = parse(\"/tmp/config.ini\")\nassert config.META.version == \"0.0.1\"\nassert config.META.root == \"/home/me/projects/mnist\"\nassert isinstance(config.misc.b, AttrDict), type(config.project.data.b)\nassert isinstance(config.misc.a, L)\n\nNotice, how the ${} variables got resolved.\nNot just that, the varaible z got computed on the fly.\nNot just that, some of the variables like list and dict got resolved into their respective python data structures.\n\nconfig.pretty()\n\n{\n    \"Data\": {\n        \"root\": \"/home/me/projects/mnist/data/\",\n        \"source\": \"https://files.fast.ai/data/examples/mnist_tiny.tgz\"\n    },\n    \"META\": {\n        \"description\": \"This is a sample\\nconfig file with a multiline\\ndescription. These are useful for\\nproject \ndescriptions/changelog/devnotes etc...\",\n        \"name\": \"mnist\",\n        \"root\": \"/home/me/projects/mnist\",\n        \"version\": \"0.0.1\"\n    },\n    \"load\": {\n        \"csv\": {\n            \"@load\": null,\n            \"root\": \"/home/me/projects/mnist/data/\"\n        },\n        \"json\": {\n            \"@load\": \"load_json_class\",\n            \"root\": \"/home/me/projects/mnist/data/\"\n        },\n        \"test\": {\n            \"@load\": \"print_root_location\",\n            \"root\": \"/home/me/projects/mnist/data/\"\n        }\n    },\n    \"misc\": {\n        \"a\": [\n            \"hello\",\n            \"hi\",\n            \"how\",\n            \"are\",\n            \"you\",\n            8000.0\n        ],\n        \"b\": {\n            \"hello\": 2,\n            \"hi\": 1\n        },\n        \"x\": 1,\n        \"y\": 20,\n        \"z\": 400.0\n    }\n}\n\n\n\n\nprint(config.META.description)\n\nThis is a sample\nconfig file with a multiline\ndescription. These are useful for\nproject descriptions/changelog/devnotes etc...\n\n\nYou can also register/call python functions/callables/classes/objects to strings by running\n\nregistry.create(\"load\")\n\n\n@registry.load.register(\"print_root_location\")\ndef printer(root):\n    return root\n\n\n@registry.load.register(\"load_csv_function\")\ndef _load_csv_function(root):\n    def load_csv_function(file):\n        return f\"Loading file from {root}/{file}\"\n\n    return load_csv_function\n\n\n@registry.load.register(\"load_json_class\")\nclass JsonLoader:\n    def __init__(self, root):\n        self.root = root\n\n    def __call__(self, file):\n        assert file.endswith(\"json\")\n        return f\"Loading file from {self.root}/{file}\"\n\n… and resolve them on parse\n\nconfig = parse_and_resolve(\"/tmp/config.ini\")\n\n\nconfig.load.test\n\n'/home/me/projects/mnist/data/'\n\n\n\nconfig.load.csv(file=\"file.csv\")\n\n'Loading file from /home/me/projects/mnist/data//file.csv'\n\n\n\nconfig.load.json(file=\"file.json\")\n\n'Loading file from /home/me/projects/mnist/data//file.json'",
    "crumbs": [
      "Registry"
    ]
  },
  {
    "objectID": "config.html",
    "href": "config.html",
    "title": "torch_snippets",
    "section": "",
    "text": "DeepLearningConfig\n\n DeepLearningConfig ()\n\n*A configuration class for deep learning models.\nThis class provides methods to access and manipulate configuration settings.\nAttributes: input_variables (list): List of input variables defined in the class constructor.\nMethods: keys(): Returns the list of input variables. getitem(key): Returns the value of the specified key. contains(key): Checks if the specified key is present in the input variables. from_ini_file(filepath, config_root=None): Creates an instance of the class from an INI file. repr(): Returns a string representation of the class.\nExample usage: config = DeepLearningConfig() config.from_ini_file(‘config.ini’) print(config.keys()) print(config[‘learning_rate’])*\n\nfrom torch_snippets.registry import parse_string\nfrom torch_snippets.torch_loader import *\nfrom torch_snippets import writelines\n\n\nconfig_str = \"\"\"\n[META]\nexperiment = mnist.v1\ndescription = Training MLP with \n    mnist data on 10k images only\n    using huggingface trainer and \n    cosine annealing\n\n[ModelConfig]\nn_layers = 3\nn_hidden = 256\nn_classes = 10\n\n[DatasetConfig]\nroot = /home/datasets/mnist\ntrain = ${root}/train\nval = ${root}/val\ntrain_subset = 10000\nval_subest = ${train_subset}//10\n\n[TrainingConfig]\nmax_steps = ${DatasetConfig.train_subset} * 5\nlearning_rate = 3e-4\noutput_dir = ./results/${META.experiment}\nper_device_train_batch_size = 256\nper_device_eval_batch_size = ${per_device_train_batch_size}\nevaluation_strategy = \"steps\"\neval_steps = 500\nlogging_strategy = ${evaluation_strategy}\nlogging_steps = ${eval_steps}//100\nsave_strategy = ${evaluation_strategy}\nsave_steps = ${eval_steps}\nsave_total_limit = 1\nseed = 1234\nlabel_names = ['targets']\nlr_scheduler_type = cosine\n\"\"\".strip()\n\nconfig = parse_string(config_str)\n\n\nclass MNIST(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(768, config.n_hidden),\n            *[\n                nn.Sequential(nn.Linear(config.n_hidden, config.n_hidden), nn.ReLU())\n                for _ in range(config.n_layers - 1)\n            ],\n            nn.Linear(config.n_hidden, config.n_classes)\n        )\n\n    def forward(self, images): ...\n\n\nmodel = MNIST(config.ModelConfig)\nprint(model)\n\nMNIST(\n  (model): Sequential(\n    (0): Linear(in_features=768, out_features=256, bias=True)\n    (1): Sequential(\n      (0): Linear(in_features=256, out_features=256, bias=True)\n      (1): ReLU()\n    )\n    (2): Sequential(\n      (0): Linear(in_features=256, out_features=256, bias=True)\n      (1): ReLU()\n    )\n    (3): Linear(in_features=256, out_features=10, bias=True)\n  )\n)\n\n\nIf needed, configs can be unpacked like a dictionary too\n\nclass MNIST(nn.Module):\n    \"\"\"\n    A PyTorch module for a multi-layer perceptron (MLP) model for MNIST classification.\n\n    Args:\n        n_hidden (int): The number of hidden units in each hidden layer.\n        n_classes (int): The number of output classes.\n        n_layers (int): The number of hidden layers in the model.\n\n    Attributes:\n        model (nn.Sequential): The sequential model that represents the MLP.\n\n    \"\"\"\n\n    def __init__(self, *, n_hidden, n_classes, n_layers):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(768, n_hidden),\n            *[\n                nn.Sequential(nn.Linear(n_hidden, n_hidden), nn.ReLU())\n                for _ in range(n_layers - 1)\n            ],\n            nn.Linear(n_hidden, n_classes)\n        )\n\n    def forward(self, images): ...\n\n\nmodel = MNIST(**config.ModelConfig)\nprint(model)\n\nMNIST(\n  (model): Sequential(\n    (0): Linear(in_features=768, out_features=256, bias=True)\n    (1): Sequential(\n      (0): Linear(in_features=256, out_features=256, bias=True)\n      (1): ReLU()\n    )\n    (2): Sequential(\n      (0): Linear(in_features=256, out_features=256, bias=True)\n      (1): ReLU()\n    )\n    (3): Linear(in_features=256, out_features=10, bias=True)\n  )\n)\n\n\n\n\n\nGenericConfig\n\n GenericConfig (**kwargs)\n\n*A configuration class for deep learning models.\nThis class provides methods to access and manipulate configuration settings.\nAttributes: input_variables (list): List of input variables defined in the class constructor.\nMethods: keys(): Returns the list of input variables. getitem(key): Returns the value of the specified key. contains(key): Checks if the specified key is present in the input variables. from_ini_file(filepath, config_root=None): Creates an instance of the class from an INI file. repr(): Returns a string representation of the class.\nExample usage: config = DeepLearningConfig() config.from_ini_file(‘config.ini’) print(config.keys()) print(config[‘learning_rate’])*\nGenericConfig is a special class that can have attributes solely based on the config file, i.e., when we are unsure what are the arguments in the config going to be\n\nwritelines(config_str.split(\"\\n\"), \"/tmp/tmp.ini\", \"w\")\ntraining_config = GenericConfig.from_ini_file(\n    \"/tmp/tmp.ini\", config_root=\"TrainingConfig\"\n)\n\n\ndef train(**kwargs):\n    for k, v in kwargs.items():\n        print(k, v)\n\n\ntrain(**training_config)\n\nmax_steps 50000\nlearning_rate 0.00030000000000000003\noutput_dir ./results/mnist.v1\nper_device_train_batch_size 256\nper_device_eval_batch_size 256\nevaluation_strategy steps\neval_steps 500\nlogging_strategy steps\nlogging_steps 5\nsave_strategy steps\nsave_steps 500\nsave_total_limit 1\nseed 1234\nlabel_names ['targets']\nlr_scheduler_type cosine",
    "crumbs": [
      "config.html"
    ]
  },
  {
    "objectID": "paths.html",
    "href": "paths.html",
    "title": "Paths",
    "section": "",
    "text": "Paths\nUtilities to manipulate Paths\n\n\nprint(P().ls())\nprint(P().resolve())\n\n[» tmp.txt, » _quarto.yml, » decorators.ipynb, » markups.ipynb, » sidebar.yml, » AttrDict.ipynb, » interactive_show.ipynb, » load_defautls.ipynb, » sklegos.ipynb, » bounding_boxes.ipynb, » show.ipynb, » pdf.ipynb, » charts.ipynb, » paths.ipynb, » nbdev.yml, » tmp.csv, » jupyter_notebook.ipynb, » config.ipynb, » misc.ipynb, » registry.ipynb, » adapters.ipynb, » report.ipynb, » .ipynb_checkpoints, » capsule.ipynb, » logging.ipynb, » inspector.ipynb, » bokeh_plotting.ipynb, » index.ipynb, » imgaug_loader.ipynb]\n/Users/apple/Code/Personal/torch_snippets/nbs\n\n\n\n!touch tmp.txt tmp.csv\n\n\nx = P()\nx.tmp__csv, x.tmp__txt, x.misc\n\n(» tmp.csv, » tmp.txt, » misc.ipynb)\n\n\n\n!rm tmp.txt tmp.misc\n\nrm: tmp.misc: No such file or directory\n\n\n\n\nPath.rm\n\n Path.rm (confirm_prompt='Are you sure you want to delete `{self}`?\n          [y/N]', silent=True, missing_ok=True, force=False,\n          dry_run=False)\n\n\n\n\nremove_file\n\n remove_file (dry_run)\n\n\n\n\nPath.cp\n\n Path.cp (to)\n\n\n\n\nPath.mv\n\n Path.mv (to)\n\n\n\n\nPath.sample\n\n Path.sample (pattern='*')\n\n\n\n\nPath.sz\n\n Path.sz ()\n\n\n\n\nPath.size\n\n Path.size ()\n\n\n\n\nPath.rmtree\n\n Path.rmtree (prompt='Really remove `{self}` and its contents? [y/n] ',\n              force=False)\n\n\np = P(\"test.txt\")\np.touch()\nlogger.info(p.size())\n\n[07/02/24 14:04:08] INFO     0 KB                                                                                                                   1417366103.py:&lt;module&gt;:3\n\n\n\nPath objects can be moved and copied\n\np = p.mv(\"test1.txt\")\nq = p.cp(\"test2.txt\")\n\nPath objects have a size, extn (extension) and parent attributes\n\nassert isinstance(q, P)\nassert q.size() == \"0 KB\"\nassert str(p) == \"test1.txt\"\nassert p.extn() == \"txt\"\nassert p.parent == P()\n\nThey can be deleted with/without a prompt\n\np.rm(force=True)\nq.rm(confirm_prompt=False)\n\nFolders can be globbed with a default of everything\n\np = P(\"../torch_snippets\")\nassert P().ls() == P().Glob()\np.Glob(\"*.py\")\n\n(#30) [» ../torch_snippets/misc.py,» ../torch_snippets/load_defaults.py,» ../torch_snippets/text_utils.py,» ../torch_snippets/_nbdev.py,» ../torch_snippets/paths.py,» ../torch_snippets/charts.py,» ../torch_snippets/pdf_loader.py,» ../torch_snippets/interactive_show.py,» ../torch_snippets/registry.py,» ../torch_snippets/markup2.py,» ../torch_snippets/_modidx.py,» ../torch_snippets/inspector.py,» ../torch_snippets/__init__.py,» ../torch_snippets/tmp.py,» ../torch_snippets/torch_loader.py,» ../torch_snippets/logger.py,» ../torch_snippets/markup.py,» ../torch_snippets/fastcores.py,» ../torch_snippets/sklegos.py,» ../torch_snippets/ipython.py...]\n\n\nYou can sample a random file from the directory\n\nq = p.sample(\"*.py\")\nInfo(f\"Sample file: `{q}`\")\nInfo(f\"Sample file size: `{q.size()}`\")\n\n                    INFO     Sample file: `../torch_snippets/load_defaults.py`                                                                      1725593160.py:&lt;module&gt;:2\n\n\n\n                    INFO     Sample file size: `0 KB`                                                                                               1725593160.py:&lt;module&gt;:3\n\n\n\n\ntry:\n    p.size()\nexcept Exception as e:\n    logger.warning(e)\n\n                    WARNING  `../torch_snippets` is a directory                                                                                     1980994904.py:&lt;module&gt;:4\n\n\n\n\np = P(\"test.txt\")\np.touch()\nassert isdir(p) == False\nassert fname(p) == \"test.txt\"\nassert parent(p) == P()\nassert stem(p) == \"test\"\nassert extn(p) == \"txt\"\n\nprint(find(\"capsule\", Glob(\"./\")))\n\np.rm(confirm_prompt=False)\n\ncapsule.ipynb\n\n\n\n\n\nlist_zip\n\n list_zip (file)\n\n\n\n\nunzip_file\n\n unzip_file (file, dest)\n\n\n\n\nzip_files\n\n zip_files (list_of_files, dest)\n\n\n!touch test1.txt test2.txt\nf = zip_files(P().Glob(\"*.txt\"), \"test.tar.gz\")\nunzip_file(f, \"./\")\n[f.rm(force=True) for f in P().Glob(\"*.txt\")]\nP(\"test.tar.gz\").rm(force=True)\n\n!touch test1.txt test2.txt\nf = zip_files(P().Glob(\"*.txt\"), \"test.zip\")\nunzip_file(f, \"./\")\n[f.rm(force=True) for f in P().Glob(\"*.txt\")]\nP(\"test.zip\").rm(force=True)\n\n                    INFO     Zipping 2 files to test.tar.gz...                                                                                     3826617683.py:zip_files:8\n\n\n\n100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00&lt;00:00, 1836.39it/s]\n\n\n[07/02/24 14:04:09] INFO     Zipping 2 files to test.zip...                                                                                        3826617683.py:zip_files:8\n\n\n\n100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00&lt;00:00, 851.46it/s]\n\n\n\n\n\nfolder_summary\n\n folder_summary (thing)\n\n\n\n\ncommon_items\n\n common_items (*fldrs, verbose=True)\n\n\n\n\nremove_duplicates\n\n remove_duplicates (files)\n\nCheck a list of files and remove duplicates based on their checksum\n\n\n\nmd5\n\n md5 (fname)\n\n\nmd5(\"paths.ipynb\")\n\n'02ae3f36d5fd54fe83c9349376ada016'\n\n\n\n\n\nPath.write_lines\n\n Path.write_lines (lines, mode)\n\n\n\n\nwritelines\n\n writelines (lines, file, mode)\n\n\n\n\nPath.read_lines\n\n Path.read_lines (silent=False, encoding=None)\n\n\n\n\nreadlines\n\n readlines (fpath, silent=False, encoding=None)\n\n\nP(\"paths.ipynb\").read_lines()[:10]\n\n                    INFO     loaded 1396 lines                                                                                                    276455267.py:read_lines:13\n\n\n\n['{',\n '\"cells\": [',\n '{',\n '\"cell_type\": \"raw\",',\n '\"metadata\": {},',\n '\"source\": [',\n '\"# Paths\\\\n\",',\n '\"Utilities to manipulate Paths\\\\n\",',\n '\"---\\\\n\",',\n '\"{}\\\\n\",']\n\n\n\n\n\ntree\n\n tree (directory='./', filelimit=50, to=None)\n\n\nP(\"../\").tree\n\n/Users/apple/Code/Personal/torch_snippets\n ── LICENSE\n ── LICENSE.txt\n ── MANIFEST\n ── MANIFEST.in\n ── Makefile\n ── README.md\n ── Screenshot 2022-09-08 at 4.40.18 PM.png\n ── _proc\n     ── _quarto.yml\n     ── nbdev.yml\n     ── sidebar.yml\n ── assets\n     ── Preamble.csv\n     ── Preamble.png\n     ── avgs0.png\n     ── avgs1.png\n     ── demo.gif\n ── backups\n     ── testing\n         ── 0000.html\n ── build\n     ── bdist.macosx-11.1-arm64\n     ── lib\n         ── torch_snippets\n             ── __init__.py\n             ── _modidx.py\n             ── _nbdev.py\n             ── adapters.py\n             ── bb_utils.py\n             ── bokeh_loader.py\n             ── charts.py\n             ── dates.py\n             ── decorators.py\n             ── fastcores.py\n             ── icecream.py\n             ── imgaug_loader.py\n             ── inspector.py\n             ── interactive_show.py\n             ── ipython.py\n             ── load_defaults.py\n             ── loader.py\n             ── logger.py\n             ── markup.py\n             ── markup2.py\n             ── misc.py\n             ── paths.py\n             ── pdf_loader.py\n             ── registry.py\n             ── scp.py\n             ── sklegos.py\n             ── text_utils.py\n             ── thinc_parser\n                 ── __init__.py\n                 ── parser.py\n             ── torch_loader.py\n             ── trainer\n                 ── __init__.py\n                 ── capsule.py\n                 ── config.py\n                 ── hooks.py\n                 ── neural_graph.py\n             ── video.py\n ── changelog.md\n ── conda\n     ── torch_snippets\n         ── meta.yaml\n ── dist\n     ── torch_snippets-0.535-py3-none-any.whl\n     ── torch_snippets-0.535.tar.gz\n ── docker-compose.yml\n ── docs\n     ── adapters.html\n     ── bokeh_plotting.html\n     ── bounding_boxes.html\n     ── bounding_boxes_files\n         ── figure-html\n             ── cell-6-output-1.png\n             ── cell-7-output-1.png\n             ── cell-8-output-1.png\n             ── cell-9-output-1.png\n     ── capsule.html\n     ── capsule_files\n         ── figure-html\n             ── cell-5-output-2.png\n     ── charts.html\n     ── config.html\n     ── decorators.html\n     ── imgaug_loader.html\n     ── imgaug_loader_files\n         ── figure-html\n             ── cell-3-output-1.png\n             ── cell-5-output-10.png\n             ── cell-5-output-12.png\n             ── cell-5-output-14.png\n             ── cell-5-output-16.png\n             ── cell-5-output-18.png\n             ── cell-5-output-2.png\n             ── cell-5-output-20.png\n             ── cell-5-output-22.png\n             ── cell-5-output-4.png\n             ── cell-5-output-6.png\n             ── cell-5-output-8.png\n             ── cell-6-output-1.png\n             ── cell-7-output-1.png\n             ── cell-8-output-2.png\n     ── index.html\n     ── inspector.html\n     ── interactive_show.html\n     ── jupyter_notebook.html\n     ── load_defautls.html\n     ── logging.html\n     ── markups.html\n     ── misc.html\n     ── paths.html\n     ── pdf.html\n     ── registry.html\n     ── report.html\n     ── report_files\n         ── figure-html\n             ── cell-3-output-2.png\n             ── cell-5-output-1.png\n     ── robots.txt\n     ── search.json\n     ── show.html\n     ── show_files\n         ── figure-html\n             ── cell-2-output-1.png\n             ── cell-3-output-1.png\n             ── cell-4-output-2.png\n             ── cell-4-output-4.png\n             ── cell-4-output-6.png\n             ── cell-5-output-1.png\n             ── cell-8-output-1.png\n             ── cell-9-output-1.png\n     ── site_libs\n         ── bootstrap\n             ── bootstrap-icons.css\n             ── bootstrap-icons.woff\n             ── bootstrap.min.css\n             ── bootstrap.min.js\n         ── clipboard\n             ── clipboard.min.js\n         ── quarto-html\n             ── anchor.min.js\n             ── popper.min.js\n             ── quarto-syntax-highlighting.css\n             ── quarto.js\n             ── tippy.css\n             ── tippy.umd.min.js\n         ── quarto-nav\n             ── headroom.min.js\n             ── quarto-nav.js\n         ── quarto-search\n             ── autocomplete.umd.js\n             ── fuse.min.js\n             ── quarto-search.js\n     ── sitemap.xml\n     ── sklegos.html\n ── nbs\n     ── AttrDict.ipynb\n     ── _quarto.yml\n     ── adapters.ipynb\n     ── bokeh_plotting.ipynb\n     ── bounding_boxes.ipynb\n     ── capsule.ipynb\n     ── charts.ipynb\n     ── config.ipynb\n     ── decorators.ipynb\n     ── imgaug_loader.ipynb\n     ── index.ipynb\n     ── inspector.ipynb\n     ── interactive_show.ipynb\n     ── jupyter_notebook.ipynb\n     ── load_defautls.ipynb\n     ── logging.ipynb\n     ── markups.ipynb\n     ── misc.ipynb\n     ── nbdev.yml\n     ── paths.ipynb\n     ── pdf.ipynb\n     ── registry.ipynb\n     ── report.ipynb\n     ── show.ipynb\n     ── sidebar.yml\n     ── sklegos.ipynb\n     ── tmp.csv\n ── quarto-macos.pkg\n ── requirements.txt\n ── scripts.ipynb\n ── settings.ini\n ── setup.cfg\n ── setup.py\n ── testing.ipynb\n ── tmp.ini\n ── torch_snippets\n     ── __init__.py\n     ── _modidx.py\n     ── _nbdev.py\n     ── adapters.py\n     ── bb_utils.py\n     ── bokeh_loader.py\n     ── charts.py\n     ── dates.py\n     ── decorators.py\n     ── fastcores.py\n     ── icecream.py\n     ── imgaug_loader.py\n     ── inspector.py\n     ── interactive_show.py\n     ── ipython.py\n     ── load_defaults.py\n     ── loader.py\n     ── logger.py\n     ── markup.py\n     ── markup2.py\n     ── misc.py\n     ── paths.py\n     ── pdf_loader.py\n     ── registry.py\n     ── scp.py\n     ── sklegos.py\n     ── text_utils.py\n     ── thinc_parser\n         ── __init__.py\n         ── parser.py\n     ── tmp.py\n     ── torch_loader.py\n     ── trainer\n         ── __init__.py\n         ── capsule.py\n         ── config.py\n         ── hooks.py\n         ── neural_graph.py\n     ── video.py\n ── torch_snippets.egg-info\n     ── PKG-INFO\n     ── SOURCES.txt\n     ── dependency_links.txt\n     ── not-zip-safe\n     ── requires.txt\n     ── top_level.txt\n\n36 directories, 206 files\n\n\n\n\nx = P()\nx.decorators.sz\n\n'13 KB'\n\n\n\n\n\nfolder_structure_to_json\n\n folder_structure_to_json (path, output_file=None)\n\nCreates a JSON file representing the folder structure of the given directory.\n\n\n\nfolder_structure_to_dict\n\n folder_structure_to_dict (path)\n\nRecursively constructs a nested dictionary that represents the folder structure.\n\nx = P(\"tmp.txt\")\nx.touch()\nx.write_lines([i for i in range(1000)], mode=\"w\")\nlines = x.read_lines()\nassert lines == [f\"{i}\" for i in range(1000)]\nlogger.info(x.size())\n\nx.rm(confirm_prompt=False)\n\n                    INFO     loaded 1000 lines                                                                                                    276455267.py:read_lines:13\n\n\n\n                    INFO     3 KB                                                                                                                   1033976698.py:&lt;module&gt;:6\n\n\n\n\n\n\nloaddill\n\n loaddill (fpath)\n\nLoad a python object from a dill file\n\n\n\ndumpdill\n\n dumpdill (obj, fpath, silent=False, message='Dumped object of size\n           ≈{fsize} @ \"{fpath}\" in {dumptime:.2e} seconds')\n\nDump a python object as a dill file (better replacement to pickle)\n\np = P(\"test.tmp\")\ndumpdill([1, 2, 3], p)\ny = loaddill(p)\np.rm(confirm_prompt=False)\nassert y == [1, 2, 3]\n\n                    INFO     Dumped object of size ≈0 KB @ \"test.tmp\" in 2.55e-04 seconds                                                            554288780.py:&lt;module&gt;:2",
    "crumbs": [
      "Paths"
    ]
  },
  {
    "objectID": "pdf.html",
    "href": "pdf.html",
    "title": "PDF",
    "section": "",
    "text": "PDF\n\n PDF (path, dfs=None, dpi=150)\n\nLoad a PDF file from path as a list of images Use show function to see the images WIP",
    "crumbs": [
      "PDF"
    ]
  },
  {
    "objectID": "bounding_boxes.html",
    "href": "bounding_boxes.html",
    "title": "Bounding Box",
    "section": "",
    "text": "Bounding Box\n\nCreate a box by mentioning the top-left (x, y) and bottom-right (X, Y) coordinates\nSay x, y, X, Y are 10, 20, 40, 50 respectively\n\nbb = BB([10, 20, 40, 50])\n\nYou get the following attributes for free\n\n\n\nbb.x=10              (top left - x)\nbb.y=20              (top left - y)\nbb.X=40              (bottom right - x)\nbb.Y=50              (bottom right - y)\nbb.w=30              (width)\nbb.h=30              (height)\nbb.xc=25.0           (center x)\nbb.yc=35.0           (center y)\nbb.c=(25.0, 35.0)    (center)\nbb.area=900          (area)\nbb.shape=(30, 30)    (height, width)\n\n\n\n\nfrom torch_snippets import show, read, P, pd\n\n[08/23/24 18:12:57] WARNING  Unable to load torch and dependent libraries from torch-snippets.                                                        d=185334;file:///Users/yeshwanth/Code/Personal/torch_snippets/torch_snippets/loader.py:108\u001b\\loader.py;;\u001b\\:d=169396;file:///Users/yeshwanth/Code/Personal/torch_snippets/torch_snippets/loader.py:108#&lt;module&gt;:108\u001b\\&lt;module&gt;:108;;\u001b\\\n                             Functionalities might be limited. pip install lovely-tensors in case there are torch related errors                                            \n\n\n\nassets = P(\"/Users/yeshwanth.y/code/torch_snippets/assets/\")\nim = read(assets / \"Preamble.png\")\ndf = pd.read_csv(assets / \"Preamble.csv\")\nshow(df.head())\ndf = to_absolute(df, *im.shape[:2])\nshow(df.head())\ndf = to_relative(df, *im.shape[:2])\nshow(df.head())\n\n\n  \n    \n      \n      x\n      y\n      X\n      Y\n      text\n      block_id\n    \n  \n  \n    \n      0\n      135\n      181\n      308\n      218\n      ConstITUtIO\n      0\n    \n    \n      1\n      156\n      264\n      217\n      284\n      NLTHE\n      1\n    \n    \n      2\n      218\n      264\n      276\n      284\n      PEOPLE\n      1\n    \n    \n      3\n      267\n      265\n      295\n      282\n      OF\n      1\n    \n    \n      4\n      297\n      264\n      341\n      284\n      INDIA,\n      1\n    \n  \n\n\n\n\n  \n    \n      \n      x\n      y\n      X\n      Y\n      text\n      block_id\n    \n  \n  \n    \n      0\n      135\n      181\n      308\n      218\n      ConstITUtIO\n      0\n    \n    \n      1\n      156\n      264\n      217\n      284\n      NLTHE\n      1\n    \n    \n      2\n      218\n      264\n      276\n      284\n      PEOPLE\n      1\n    \n    \n      3\n      267\n      265\n      295\n      282\n      OF\n      1\n    \n    \n      4\n      297\n      264\n      341\n      284\n      INDIA,\n      1\n    \n  \n\n\n\n\n  \n    \n      \n      x\n      y\n      X\n      Y\n      text\n      block_id\n    \n  \n  \n    \n      0\n      0.249538\n      0.253501\n      0.569316\n      0.305322\n      ConstITUtIO\n      0\n    \n    \n      1\n      0.288355\n      0.369748\n      0.401109\n      0.397759\n      NLTHE\n      1\n    \n    \n      2\n      0.402957\n      0.369748\n      0.510166\n      0.397759\n      PEOPLE\n      1\n    \n    \n      3\n      0.493530\n      0.371148\n      0.545287\n      0.394958\n      OF\n      1\n    \n    \n      4\n      0.548983\n      0.369748\n      0.630314\n      0.397759\n      INDIA,\n      1\n    \n  \n\n\n\n\nshow(im, df=df, sz=10)\n\n\n\n\n\n\n\n\n\nshow(im, df=to_absolute(df, *im.shape[:2]), sz=10)\n\n\n\n\n\n\n\n\n\n_df = to_absolute(df, *im.shape[:2])\nshow(im, df=to_relative(_df, *im.shape[:2]), sz=10)\n\n\n\n\n\n\n\n\n\n_df = combine_xyXY_to_bb(_df)\nshow(im, df=to_relative(_df, *im.shape[:2]), sz=10)\n\n\n\n\n\n\n\n\n\nto_relative(_df, *im.shape[:2])\n\n\n\n\n\n\n\n\ntext\nblock_id\nbb\n\n\n\n\n0\nConstITUtIO\n0\n[0.24953789279112754, 0.2535014005602241, 0.56...\n\n\n1\nNLTHE\n1\n[0.28835489833641403, 0.3697478991596639, 0.40...\n\n\n2\nPEOPLE\n1\n[0.4029574861367837, 0.3697478991596639, 0.510...\n\n\n3\nOF\n1\n[0.49353049907578556, 0.3711484593837535, 0.54...\n\n\n4\nINDIA,\n1\n[0.5489833641404805, 0.3697478991596639, 0.630...\n\n\n...\n...\n...\n...\n\n\n68\nGIVE\n13\n[0.4011090573012939, 0.7366946778711485, 0.478...\n\n\n69\nTO\n13\n[0.4879852125693161, 0.7366946778711485, 0.536...\n\n\n70\noUrSELVES\n13\n[0.5508317929759704, 0.7394957983193278, 0.706...\n\n\n71\nTHIS\n13\n[0.7190388170055453, 0.7366946778711485, 0.783...\n\n\n72\nCONSTITUTION.\n14\n[0.23290203327171904, 0.7689075630252101, 0.44...\n\n\n\n\n73 rows × 3 columns\n\n\n\n\n\nisin\n\n isin (bboxes1, bboxes2, return_matrix=True)\n\nreturn indexes of those boxes from bboxes1 that are completely inside bboxes2\n\n\n\nmerge_by_bb\n\n merge_by_bb (df1, df2, suffixes=('_x', '_y'), iou_threshold=0.1)\n\nMerge df1 columns to df2 by using iou Make sure both df1 & df2 are relative or both absolute",
    "crumbs": [
      "Bounding Box"
    ]
  },
  {
    "objectID": "load_defautls.html",
    "href": "load_defautls.html",
    "title": "File Exists",
    "section": "",
    "text": "File Exists\nand what to do if it doesn’t\n\n\n\nloadifexists\n\n loadifexists (fpath, default)\n\nLoad data from a dill file if it exists, else return default value\n\n\n\nexists\n\n exists (fpath)\n\nAlias for os.path.exists",
    "crumbs": [
      "File Exists"
    ]
  },
  {
    "objectID": "AttrDict.html",
    "href": "AttrDict.html",
    "title": "torch_snippets",
    "section": "",
    "text": "from torch_snippets.loader import L\n\n[07/01/24 11:12:47] WARNING  Unable to load torch and dependent libraries from torch-snippets.                                                        loader.py:&lt;module&gt;:108\n                             Functionalities might be limited. pip install lovely-tensors in case there are torch related errors                                            \n\n\n\n\nclass AD(object):\n    forbidden = set(\":,'\\\"}{.\")\n\n    def __init__(self, *args, given_input_to_ad=None, **kwargs):\n        given_input_to_ad = {} if given_input_to_ad is None else given_input_to_ad\n        if len(args) == 1 and isinstance(args[0], (Mapping, AttrDict)):\n            given_input_to_ad = args[0]\n            args = {}\n        else:\n            _args = dict(ic.io(*args)) if len(args) &gt; 0 else {}\n            args = {}\n            for k, v in _args.items():\n                if any(c in self.forbidden for c in k):\n                    assert isinstance(\n                        v, (dict, AttrDict)\n                    ), f\"Input `{v}` can't be a list\"\n                    given_input_to_ad = {**v, **given_input_to_ad}\n                else:\n                    args = {**{k: v}, **args}\n\n        given_input_to_ad = {**kwargs, **given_input_to_ad, **args}\n        for name, value in given_input_to_ad.items():\n            setattr(self, str(name), self._wrap(value))\n\n    def items(self):\n        return self.__dict__.items()\n\n    def keys(self):\n        return self.__dict__.keys()\n\n    def values(self):\n        return self.__dict__.values()\n\n    def __json__(self):\n        return self.to_dict()\n\n    def _wrap(self, value):\n        if isinstance(value, (L, tuple, list, set, frozenset)):\n            value = type(value)([self._wrap(v) for v in value])\n            if isinstance(value, (list, L)):\n                value = L(value)\n            return value\n        else:\n            return (\n                AttrDict(given_input_to_ad=value) if isinstance(value, dict) else value\n            )\n\n    __getitem__ = lambda self, x: (\n        AttrDict({_x: self[_x] for _x in x})\n        if isinstance(x, (list, L))\n        else getattr(self, str(x))\n    )\n    __setitem__ = lambda self, k, v: setattr(self, str(k), self._wrap(v))\n\n    def update(self, dict):\n        for k, v in dict.items():\n            self[k] = v\n\n    def get(self, key, default=None):\n        key = str(key)\n        return self[key] if key in self else default\n\n    def __iter__(self):\n        return iter(self.keys())\n\n    def __len__(self):\n        return len(self.keys())\n\n    def __repr__(self):\n        return f\"\\n```↯ AttrDict ↯\\n{self.summary()}\\n```\\n\"\n\n    def __dir__(self):\n        return self.__dict__.keys()\n\n    def __contains__(self, key):\n        key = str(key)\n        if \".\" not in key:\n            return key in self.__dict__.keys()\n        else:\n            d = self\n            for _k in key.split(\".\"):\n                try:\n                    d = d[_k]\n                except AttributeError:\n                    return False\n            return True\n\n    def __delitem__(self, key):\n        key = str(key)\n        del self.__dict__[key]\n\n    def map(self, func):\n        for k in dir(self):\n            v = self[k]\n            if isinstance(v, AttrDict):\n                v.map(func)\n            elif isinstance(v, (L, tuple, list, set, frozenset)):\n                v = [_v.map(func) if isinstance(_v, AttrDict) else func(_v) for _v in v]\n            else:\n                v = func(v)\n            self[k] = v\n\n    def drop(self, key):\n        if key in self:\n            del self[key]\n        for k in dir(self):\n            v = self[k]\n            if isinstance(v, AttrDict):\n                v.drop(key)\n            if isinstance(v, (L, tuple, list, set, frozenset)):\n                v = [_v.drop(key) for _v in v if isinstance(_v, AttrDict)]\n\n    def to_dict(self):\n        d = {}\n        for k in self.__dict__.keys():  # can't use dir here\n            v = self[k]\n            if isinstance(v, AttrDict):\n                v = v.to_dict()\n            if isinstance(v, (L, tuple, list, set, frozenset)):\n                v = [_v.to_dict() if isinstance(_v, AttrDict) else _v for _v in v]\n            d[k] = v\n        return d\n\n    dict = to_dict\n\n    def pretty(self, print_with_logger=False, *args, **kwargs):\n        pretty_json(\n            self.to_dict(), print_with_logger=print_with_logger, *args, **kwargs\n        )\n\n    def __eq__(self, other):\n        return AttrDict(given_input_to_ad=other).to_dict() == self.to_dict()\n\n    def find_address(self, key, current_path=\"\"):\n        addresses = []\n        for k in self.keys():\n            if current_path:\n                new_path = f\"{current_path}.{k}\"\n            else:\n                new_path = k\n\n            if k == key:\n                addresses.append(new_path)\n\n            if isinstance(self[k], AttrDict):\n                addresses.extend(self[k].find_address(key, new_path))\n\n            elif isinstance(self[k], (L, tuple, list, set, frozenset)):\n                for i, item in enumerate(self[k]):\n                    if isinstance(item, AttrDict):\n                        addresses.extend(item.find_address(key, f\"{new_path}.{i}\"))\n        return addresses\n\n    def summary(self, current_path=\"\", depth=0, sep=\"  \", max_items=10):\n        max_items = int(os.environ.get(\"AD_MAX_ITEMS\", max_items))\n        sep = os.environ.get(\"AD_SEP\", sep)\n\n        def format_path(path, key):\n            return f\"{path}.{key}\" if path else key\n\n        def format_item(key, item, path, depth, sep):\n            import numpy as np\n            import pandas as pd\n\n            try:\n                import torch\n            except ModuleNotFoundError:\n\n                class Torch:\n                    Tensor = type(None)\n\n                torch = Torch()\n\n            if isinstance(item, (pd.DataFrame,)):\n                return f\"{sep * depth}{key} - {type(item).__name__} - shape {item.shape} - columns {item.columns} - {hash_pandas_dataframe(item)}\\n\"\n            if isinstance(item, AttrDict) or hasattr(item, \"keys\"):\n                item = AttrDict(**item)\n                return f\"{sep*depth}{key}\\n\" + item.summary(path, depth + 1, sep)\n            elif isinstance(item, (list, tuple, set, frozenset, L)):\n                return summarize_collection(key, item, path, depth + 1, sep)\n            elif isinstance(item, (torch.Tensor, np.ndarray)):\n                is_np = False\n                if isinstance(item, np.ndarray):\n                    is_np = True\n                    item = torch.tensor(item)\n                is_np = \"🔦\" if not is_np else \"np.\"\n                return f\"{sep * depth}{key} - {is_np}{item} - {hash_tensor(item)}\\n\"\n\n            else:\n                is_multiline = False\n                ogitem = item\n                if isinstance(item, (str, P)):\n                    item = str(item)\n                    is_multiline = \"\\n\" in item\n                    _sep = \" ...\\n...\\n...\\n...\\n... \" if is_multiline else \".........\"\n                    if len(item) &gt; 100:\n                        item = item[:35] + _sep + item[-35:]\n                    if is_multiline:\n                        _item = item.split(\"\\n\")\n                        _item = \"\\n\".join([f\"{sep*(depth+1)}{l}\" for l in _item])\n                        item = f\"↓\\n{sep*(depth+1)}```\\n{_item}\\n{sep*(depth+1)}```\"\n                multiline = \"\" if not is_multiline else \"Multiline \"\n                return f\"{sep * depth}{key} - {item} (🏷️ {multiline}{type(ogitem).__name__})\\n\"\n\n        def summarize_collection(key, collection, path, d, s):\n            summary_str = f\"{s * (d - 1)}{key}\\n\"\n            for i, item in enumerate(collection):\n                item_path = format_path(path, i)\n                if i &lt; max_items:\n                    summary_str += format_item(i, item, item_path, d, s)\n                else:\n                    summary_str += (\n                        f\"{s*d}... {len(collection) - max_items} more items ...\\n\"\n                    )\n                    break\n            return summary_str\n\n        summary_str = \"\"\n        for ix, key in enumerate(self.keys()):\n            if ix &gt;= max_items:\n                summary_str += (\n                    f\"{sep*depth} ... {len(self.keys()) - max_items} more keys ...\\n\"\n                )\n                break\n            new_path = format_path(current_path, key)\n            summary_str += format_item(key, self[key], new_path, depth, sep)\n        return summary_str\n\n    def print_summary(self, **kwargs):\n        from builtins import print\n\n        print(self.summary(**kwargs))\n\n    def write_summary(self, to, **kwargs):\n        writelines(self.summary(**kwargs).split(\"\\n\"), to)\n\n    def fetch(self, addr):\n        if isinstance(addr, (list, L)):\n            return L([self.fetch(_addr) for _addr in addr])\n\n        o = self\n        for p in addr.split(\".\"):\n            try:\n                o = o[int(p)]\n            except:\n                o = o[p]\n        return o\n\n\nx = AD(x=1)\nx\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nFile ~/miniconda3/miniconda3/envs/ts/lib/python3.10/site-packages/IPython/core/formatters.py:708, in PlainTextFormatter.__call__(self, obj)\n    701 stream = StringIO()\n    702 printer = pretty.RepresentationPrinter(stream, self.verbose,\n    703     self.max_width, self.newline,\n    704     max_seq_length=self.max_seq_length,\n    705     singleton_pprinters=self.singleton_printers,\n    706     type_pprinters=self.type_printers,\n    707     deferred_pprinters=self.deferred_printers)\n--&gt; 708 printer.pretty(obj)\n    709 printer.flush()\n    710 return stream.getvalue()\n\nFile ~/miniconda3/miniconda3/envs/ts/lib/python3.10/site-packages/IPython/lib/pretty.py:410, in RepresentationPrinter.pretty(self, obj)\n    407                         return meth(obj, self, cycle)\n    408                 if cls is not object \\\n    409                         and callable(cls.__dict__.get('__repr__')):\n--&gt; 410                     return _repr_pprint(obj, self, cycle)\n    412     return _default_pprint(obj, self, cycle)\n    413 finally:\n\nFile ~/miniconda3/miniconda3/envs/ts/lib/python3.10/site-packages/IPython/lib/pretty.py:778, in _repr_pprint(obj, p, cycle)\n    776 \"\"\"A pprint that just redirects to the normal repr function.\"\"\"\n    777 # Find newlines and replace them with p.break_()\n--&gt; 778 output = repr(obj)\n    779 lines = output.splitlines()\n    780 with p.group():\n\nCell In[8], line 69, in AD.__repr__(self)\n     68 def __repr__(self):\n---&gt; 69     return f\"\\n```↯ AttrDict ↯\\n{self.summary()}\\n```\\n\"\n\nCell In[8], line 154, in AD.summary(self, current_path, depth, sep, max_items)\n    153 def summary(self, current_path=\"\", depth=0, sep=\"  \", max_items=10):\n--&gt; 154     max_items = int(os.environ.get(\"AD_MAX_ITEMS\", max_items))\n    155     sep = os.environ.get(\"AD_SEP\", sep)\n    157     def format_path(path, key):\n\nNameError: name 'os' is not defined",
    "crumbs": [
      "AttrDict.html"
    ]
  },
  {
    "objectID": "decorators.html",
    "href": "decorators.html",
    "title": "Decorator Utilites",
    "section": "",
    "text": "check_kwargs_not_none\n\n check_kwargs_not_none (func)\n\n*A decorator that checks if any keyword argument is None. Raises a ValueError if any argument is None.\nArgs: func: The function to be decorated.\nReturns: The decorated function.\nRaises: ValueError: If any keyword argument is None.*\n\n\n\nio\n\n io (func)\n\n*A decorator that inspects the inputs and outputs of a function.\nArgs: func: The function to be decorated.\nReturns: The decorated function.*\n\n\n\ntimeit\n\n timeit (func)\n\n*A decorator that measures the execution time of a function.\nArgs: func (callable): The function to be timed.\nReturns: callable: The wrapped function.\nExample: @timeit def my_function(): # code to be timed pass\nmy_function()  # prints the execution time of my_function*\n\n\n\nwarn_on_fail\n\n warn_on_fail (func)\n\n\n\n\nformat\n\n format (input)\n\n\n@timeit\n@io\ndef foo(a, b):\n    \"\"\"\n    This function takes two arguments, `a` and `b`, and returns their sum.\n\n    Parameters:\n    a (int): The first number.\n    b (int): The second number.\n\n    Returns:\n    int: The sum of `a` and `b`.\n    \"\"\"\n    import time\n\n    time.sleep(1)\n    return a + b\n\n\nfoo(10, 11)\n\n══════════════════════════════════════════════════════════════════\nINPUTS:ARGS:\ntuple of 2 items\n    int: 10\n    int: 11\n══════════════════════════════════════════════════════════════════\n══════════════════════════════════════════════════════════════════\nOUTPUTS:\nint: 21\n══════════════════════════════════════════════════════════════════\n[08/23/24 18:13:00] INFO     foo took 1.00 seconds to execute                                                                      d=60504;file://&lt;ipython-input-1-6ac2073623b5&gt;:47\u001b\\&lt;ipython-input-1-6ac2073623b5&gt;;;\u001b\\:d=369021;file://&lt;ipython-input-1-6ac2073623b5&gt;:47#wrapper:47\u001b\\wrapper:47;;\u001b\\\n\n\n21\n\n\n\n@check_kwargs_not_none\n@io\ndef foo(*, a=None, b=None):\n    return a + b\n\n\nfoo(a=None, b=10)\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[34], line 6\n      1 @check_kwargs_not_none\n      2 @io\n      3 def foo(*, a=None, b=None):\n      4     return a + b\n----&gt; 6 foo(a=None, b=10)\n\nCell In[32], line 32, in check_kwargs_not_none.&lt;locals&gt;.wrapper(*args, **kwargs)\n     30 for key, value in kwargs.items():\n     31     if value is None:\n---&gt; 32         raise ValueError(f\"Input argument '{key}' cannot be None\")\n     33 return func(*args, **kwargs)\n\nValueError: Input argument 'a' cannot be None\n\n\n\n\nimport nbdev\n\nnbdev.nbdev_export()",
    "crumbs": [
      "Decorator Utilites"
    ]
  },
  {
    "objectID": "markups.html",
    "href": "markups.html",
    "title": "Markups",
    "section": "",
    "text": "AttrDict\n\n AttrDict (*args, given_input_to_ad=None, **kwargs)\n\n*Utility class to interact with a dictionary as if it were an object. AD is an alias to this class\nFEATURES: 0. Access and modify keys (including nested keys) as if they were object attributes, supporting tab-completion. Example: self.key1.key2[0].key3 1. Keys and values are recursively converted to AttrDict instances. 2. Pretty-print the dictionary using print. 3. Convert the entire structure to a regular dictionary at any time using self.to_dict() / self.dict(). 3. Recursively remove keys using self.drop(key) from a JSON object. 4. Apply a function to all values at all levels using map.\nGOTCHAS: 1. All integer keys are implicitly converted to strings due to the enforced self.key format. 2. You can still use self[int], but this internally converts the integer to a string.\nMETHODS: - items(): Return the items of the AttrDict as key-value pairs. - keys(): Return the keys of the AttrDict. - values(): Return the values of the AttrDict. - update(dict): Update the AttrDict with key-value pairs from another dictionary. - get(key, default=None): Get the value associated with a key, with an optional default value. - __iter__(): Allow iteration over the keys of the AttrDict. - __len__(): Return the number of keys in the AttrDict. - __repr__(): Return a string representation of the AttrDict. - __dir__(): List the keys of the AttrDict as attributes. - __contains__(key): Check if a key exists in the AttrDict, use ‘a.b.c’ notation to directly check for a nested attribute. - __delitem__(key): Delete a key from the AttrDict. - map(func): Apply a function to all values in the AttrDict. - drop(key): Recursively remove a key and its values from the AttrDict. - to_dict(): Convert the AttrDict and its nested structure to a regular dictionary. - pretty(print_with_logger=False, *args, **kwargs): Pretty-print the AttrDict as JSON. - __eq__(other): Compare the AttrDict with another dictionary for equality. - find_address(key, current_path=\"\"): Find and return all addresses (paths) of a given key in the AttrDict. - summary(current_path='', summary_str='', depth=0, sep='  '): Generate a summary of the structure and values in the AttrDict. - write_summary(to, **kwargs): Write the summary to a file or stream. - fetch(addr): Retrieve a value at a specified address (path).\nPARAMETERS: - data (dict, optional): Initial data to populate the AttrDict.\nUSAGE: - Create an AttrDict instance by providing an optional initial dictionary, and then access and manipulate its contents as if they were object attributes.\nEXAMPLE:\nmy_dict = {'name': 'John', 'age': 30, 'address': {'city': 'New York', 'zip': '10001'}}\nattr_dict = AttrDict(my_dict)\nprint(attr_dict.name)  # Access values like attributes\nattr_dict.address.city = 'Los Angeles'  # Modify nested values\n```*\n\n\n::: {#bfb4146f-90bf-42bc-bf40-69fb6d612ea2 .cell tags='[]' execution_count=5}\n``` {.python .cell-code}\nxx = AttrDict({\"a\": 1, \"b\": [{\"c\": 2, \"d\": 4}, {\"e\": 3}], \"f\": {\"g\": {\"h\": 20}}})\nprint(type(xx.b[0]))\nprint(type(xx.to_dict()[\"b\"][0]))\nprint(\"f.g.h\" in xx)\nxx.pretty()\n\n&lt;class 'torch_snippets.markup2.AttrDict'&gt;\n&lt;class 'dict'&gt;\nTrue\n{\n    \"a\": 1,\n    \"b\": [\n        {\n            \"c\": 2,\n            \"d\": 4\n        },\n        {\n            \"e\": 3\n        }\n    ],\n    \"f\": {\n        \"g\": {\n            \"h\": 20\n        }\n    }\n}\n\n:::\n\nx = {\"abc\": {\"b\": 10, \"c\": 11}, \"d\": {\"e\": {\"f\": [2, {\"abc\": \"pqrs\"}, 2.234]}}}\n\ny = AttrDict(x)\n\nassert y.abc.b == 10\nassert y.d.e.f == [2, {\"abc\": \"pqrs\"}, 2.234]\n\ny.d.e.g = 11\n\n# del y.abc.c\n# OR\ndel y[\"abc\"][\"c\"]\n\nassert y.to_dict() == {\n    \"abc\": {\"b\": 10},\n    \"d\": {\"e\": {\"f\": [2, {\"abc\": \"pqrs\"}, 2.234], \"g\": 11}},\n}\n\ny.pretty(indent=2)\n\nassert \"abc\" in y\nassert \"def\" not in y\nprint(\"e\" in y.d)\n\n{\n  \"abc\": {\n    \"b\": 10\n  },\n  \"d\": {\n    \"e\": {\n      \"f\": [\n        2,\n        {\n          \"abc\": \"pqrs\"\n        },\n        2.234\n      ],\n      \"g\": 11\n    }\n  }\n}\nTrue\n\n\n\nx = {\"abc\": {\"b\": 10, \"c\": 11}, \"d\": {\"e\": {\"f\": [2, {\"abc\": \"pqrs\"}, 2.234]}}}\ny = AttrDict(x)\ny.abc[[\"b\", \"c\"]]\n\n\n```↯ AttrDict ↯\nb - 10 (🏷️ int)\nc - 11 (🏷️ int)\n\n```\n\n\n\n\n\nwrite_json\n\n write_json (obj, fpath, silent=False)\n\n\n\n\nread_json\n\n read_json (fpath)\n\n\ntry:\n    import torch\n\n    d = AD(a=torch.Tensor([1, 2, 3]), b=\"hello\")\n    write_json(d, \"/tmp/tmp.json\")\n    print(\"\\n\".join(readlines(\"/tmp/tmp.json\")))\nexcept ModuleNotFoundError:\n    ...\n\n\nd = [1, {1: 1, 2: 2}, 3]\n\npretty_json({1: 1, 2: 2})\npretty_json(d)\n\nf = write_json(d, \"/tmp/test.json\")\nprint(f)\nread_json(f)\n\n/tmp/test.json\n\n\n[1, {'1': 1, '2': 2}, 3]\n\n\n\n\n\nread_jsonl\n\n read_jsonl (file)\n\n\n\n\nwrite_jsonl\n\n write_jsonl (items, dest, mode='a')\n\n\n\n\nwrite_yaml\n\n write_yaml (content, fpath)\n\n\n\n\nread_yaml\n\n read_yaml (file)\n\n\n\n\nwrite_xml\n\n write_xml (data:Union[torch_snippets.markup2.AttrDict,dict],\n            file_path:Union[str,pathlib.Path])\n\n\n\n\nread_xml\n\n read_xml (file_path:Union[str,pathlib.Path])\n\nRead xml data as a dictionary\n\ny.to_dict()\n\n{'abc': {'b': 10, 'c': 11}, 'd': {'e': {'f': [2, {'abc': 'pqrs'}, 2.234]}}}\n\n\n\ny\n\n\n```↯ AttrDict ↯\nabc\n  b - 10 (🏷️ int)\n  c - 11 (🏷️ int)\nd\n  e\n    f\n      0 - 2 (🏷️ int)\n      1\n        abc - pqrs (🏷️ str)\n      2 - 2.234 (🏷️ float)\n\n```",
    "crumbs": [
      "Markups"
    ]
  },
  {
    "objectID": "interactive_show.html",
    "href": "interactive_show.html",
    "title": "torch_snippets",
    "section": "",
    "text": "ishow\n\n ishow (im, df, additional_attrs=None, **kwargs)\n\n\n\n\ndf2graph_nodes\n\n df2graph_nodes (df, text_attr='text', additional_attrs=None)\n\n\n\n\nviz2\n\n viz2 (graph, node_attrs=None, undirected=True, **kwargs)\n\n\n\n\nconvert_to_nx\n\n convert_to_nx (g, node_attrs=None, undirected=True)\n\n\n\n\ntolist\n\n tolist (i)\n\n\n\n\ntonp\n\n tonp (i)\n\n\n\n\nplot_graph\n\n plot_graph (g, output, im=None, **kwargs)\n\n\n\n\nplot_image\n\n plot_image (p, image, sz)\n\n\n\n\nto_networkx\n\n to_networkx (data, node_attrs:Optional[Iterable[str]]=None,\n              edge_attrs:Optional[Iterable[str]]=None,\n              graph_attrs:Optional[Iterable[str]]=None,\n              to_undirected:Union[bool,str,NoneType]=False,\n              remove_self_loops:bool=False)",
    "crumbs": [
      "interactive_show.html"
    ]
  },
  {
    "objectID": "sklegos.html",
    "href": "sklegos.html",
    "title": "SK-Legos",
    "section": "",
    "text": "SK-Legos\nUtilities to do common ML tasks\n\nYou can find 1. train_test_split which also resets the dataframes’ indexes 2. MakeFrame 3. ImputeMisingValues 4. Cat2Num 5. Other scikit-lego blocks that I use a lot\n\n\nMakeFrame\n\n MakeFrame (column_names)\n\nConvert sklearn’s output to a pandas dataframe Especially useful when working with an ensemble of models\nUsage\nCall MakeFrame as the last component in your pipeline with the desired column names.\npipeline = Pipeline([\n    ...,\n    ('output', MakeFrame(['outlier', 'class'])),\n])\n\nRefer to this notebook for an example\n\n\n\n\nImputeMissingValues\n\n ImputeMissingValues (num_mode=&lt;function mean at 0x11a0325f0&gt;,\n                      cat_mode='MISSING')\n\n*DataFrame input - DataFrame output During fit - 1. Store imputable value for each column During transform - 2. Impute missing values with imputable value 3. Create a ’{col}_na’ boolean column to tell if cells contained missing value*\n\n\n\nLambdaTransformer\n\n LambdaTransformer (fn)\n\n*Base class for all estimators in scikit-learn.\nInheriting from this class provides default implementations of:\n\nsetting and getting parameters used by GridSearchCV and friends;\ntextual and HTML representation displayed in terminals and IDEs;\nestimator serialization;\nparameters validation;\ndata validation;\nfeature names validation.\n\nRead more in the :ref:User Guide &lt;rolling_your_own_estimator&gt;.*\n\n\n\nMakeFrame\n\n MakeFrame (column_names)\n\n*Base class for all estimators in scikit-learn.\nInheriting from this class provides default implementations of:\n\nsetting and getting parameters used by GridSearchCV and friends;\ntextual and HTML representation displayed in terminals and IDEs;\nestimator serialization;\nparameters validation;\ndata validation;\nfeature names validation.\n\nRead more in the :ref:User Guide &lt;rolling_your_own_estimator&gt;.*\n\n\n\nCat2Num\n\n Cat2Num ()\n\n*Base class for all estimators in scikit-learn.\nInheriting from this class provides default implementations of:\n\nsetting and getting parameters used by GridSearchCV and friends;\ntextual and HTML representation displayed in terminals and IDEs;\nestimator serialization;\nparameters validation;\ndata validation;\nfeature names validation.\n\nRead more in the :ref:User Guide &lt;rolling_your_own_estimator&gt;.*\n\n\n\nSplitDateColumn\n\n SplitDateColumn (column_names, has_date, has_time, date_format=None)\n\n*Base class for all estimators in scikit-learn.\nInheriting from this class provides default implementations of:\n\nsetting and getting parameters used by GridSearchCV and friends;\ntextual and HTML representation displayed in terminals and IDEs;\nestimator serialization;\nparameters validation;\ndata validation;\nfeature names validation.\n\nRead more in the :ref:User Guide &lt;rolling_your_own_estimator&gt;.*",
    "crumbs": [
      "SK-Legos"
    ]
  },
  {
    "objectID": "show.html",
    "href": "show.html",
    "title": "Show",
    "section": "",
    "text": "Show is intended to show numpy-arrays/PIL-images\n\nfrom torch_snippets import *\n\nim = np.random.rand(100, 100)\nshow(im)\n\n\n\n\n\n\n\n\n\nshow(im, sz=4)\n\n\n\n\n\n\n\n\nShow will even accept pytorch Tensors and show them as images, even if they are on GPU and have channels first\nIt can accept bounding boxes as tuples of (x,y,X,Y) which can be integers (i.e., absolute coordinates) or fractions (between \\([0,1]\\)). There’s provision to give bb_colors and texts as well\n\nshow(im, bbs=[(0, 0, 0.5, 0.35), (0, 0.2, 0.35, 0.95)])\n\nshow(im, bbs=[(0, 0, 0.5, 0.35), (0, 0.2, 0.35, 0.95)], bb_colors=[\"r\", \"g\"])\n\nshow(\n    im,\n    bbs=[(0, 0, 0.5, 0.35), (0, 0.2, 0.35, 0.95)],\n    bb_colors=[\"b\", \"g\"],\n    texts=[\"bb1\", \"bb2\"],\n    sz=10,\n    text_sz=15,\n)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nIt can also read a file path directly and display the image\n\nshow(\"../docs/images/company_logo_big.png\", sz=3)\n\n\n\n\n\n\n\n\nif the input is not an image or string, show will simply display the given input as intended by jupyter notebook\n\ndf = pd.DataFrame(np.random.rand(100, 2))\nshow(df)\n\n\n\n\n\n\n\n\n0\n1\n\n\n\n\n0\n0.242478\n0.929517\n\n\n1\n0.971890\n0.506750\n\n\n2\n0.139826\n0.753227\n\n\n3\n0.864799\n0.524166\n\n\n4\n0.563610\n0.135709\n\n\n...\n...\n...\n\n\n95\n0.379874\n0.639771\n\n\n96\n0.993731\n0.811343\n\n\n97\n0.621683\n0.763054\n\n\n98\n0.844509\n0.915156\n\n\n99\n0.314272\n0.392418\n\n\n\n\n100 rows × 2 columns\n\n\n\n\nchart = Chart(df).mark_circle().encode(x=\"0:Q\", y=\"1:Q\")\nshow(chart.interactive())\n\n\n\n\n\n\n\n\ndisplay multiple images Subplots is a wapper around plt.subplots that accepts a list of images, number of columns as nc and additional kwargs\n\nfrom torch_snippets import subplots\n\nims = [np.random.rand(100, 100) for _ in range(16)]\n\nsubplots(ims, nc=4, sz=5)\n\n\n\n\n\n\n\n\n\nsubplots(\n    ims,\n    nc=2,\n    sz=(5, 15),\n    suptitle=\"RANDOM IMAGES\",\n    titles=[f\"random_{i}\" for i in range(16)],\n)",
    "crumbs": [
      "Show"
    ]
  },
  {
    "objectID": "show.html#subplots",
    "href": "show.html#subplots",
    "title": "Show",
    "section": "",
    "text": "display multiple images Subplots is a wapper around plt.subplots that accepts a list of images, number of columns as nc and additional kwargs\n\nfrom torch_snippets import subplots\n\nims = [np.random.rand(100, 100) for _ in range(16)]\n\nsubplots(ims, nc=4, sz=5)\n\n\n\n\n\n\n\n\n\nsubplots(\n    ims,\n    nc=2,\n    sz=(5, 15),\n    suptitle=\"RANDOM IMAGES\",\n    titles=[f\"random_{i}\" for i in range(16)],\n)",
    "crumbs": [
      "Show"
    ]
  },
  {
    "objectID": "charts.html",
    "href": "charts.html",
    "title": "Altair and Other Charts",
    "section": "",
    "text": "Altair and Other Charts\n\n\nfrom torch_snippets.loader import *\nfrom sklearn.datasets import make_moons\n\nnp.random.seed(10)\nx, y = make_moons(1000, noise=0.1)\ndf = pd.DataFrame({\"x1\": x[:, 0], \"x2\": x[:, 1], \"y\": y})\n\nChart(df).mark_circle().encode(x=\"x1:Q\", y=\"x2:Q\", color=\"y:N\").interactive()\n\n\n\n\n\n\n\nRefer to altair-viz.github.io for more awesome charts.\ntorch-snippets exposes a confusion matrix function CM as an example\n\nMethod 1\n\nn = 10\na = \"qwertyuiopasdfghjklzxcvbnm\"\ntruth = np.random.randint(4, size=1000000)\npred = np.random.randint(4, size=1000000)\nshow(CM(truth=truth, pred=pred, mapping={i: a for i, a in enumerate(a)}))\n# mapping is optional\n\n              precision    recall  f1-score   support\n\n           0       0.25      0.25      0.25    250150\n           1       0.25      0.25      0.25    250245\n           2       0.25      0.25      0.25    249836\n           3       0.25      0.25      0.25    249769\n\n    accuracy                           0.25   1000000\n   macro avg       0.25      0.25      0.25   1000000\nweighted avg       0.25      0.25      0.25   1000000\n\n\n\n\n\n\n\n\n\n\n\nMethod 2\n\ndf = pd.DataFrame(\n    {\n        \"truth\": [randint(n) for _ in range(1000)],\n        \"pred\": [randint(n) for _ in range(1000)],\n    }\n)\nshow(CM(df, \"truth\", \"pred\", mapping={i: a for i, a in enumerate(a)}))\n# mapping is optional\n\n              precision    recall  f1-score   support\n\n           0       0.13      0.14      0.13        92\n           1       0.08      0.09      0.08       101\n           2       0.13      0.12      0.13       107\n           3       0.06      0.06      0.06       105\n           4       0.12      0.11      0.11        94\n           5       0.12      0.09      0.10       115\n           6       0.08      0.10      0.09        88\n           7       0.08      0.07      0.08       113\n           8       0.09      0.09      0.09        99\n           9       0.12      0.15      0.13        86\n\n    accuracy                           0.10      1000\n   macro avg       0.10      0.10      0.10      1000\nweighted avg       0.10      0.10      0.10      1000\n\n\n\n\n\n\n\n\n\n\n\nMethod 3\n\ndf = pd.DataFrame(\n    {\n        \"truth\": [choose(\"abcd\") for _ in range(1000)],\n        \"pred\": [choose(\"abcd\") for _ in range(1000)],\n    }\n)\nshow(CM(df, \"truth\", \"pred\"))\n# mapping is optional\n\n              precision    recall  f1-score   support\n\n           a       0.25      0.29      0.27       229\n           b       0.28      0.29      0.28       256\n           c       0.27      0.24      0.26       267\n           d       0.26      0.25      0.25       248\n\n    accuracy                           0.27      1000\n   macro avg       0.26      0.27      0.26      1000\nweighted avg       0.27      0.27      0.26      1000\n\n\n\n\n\n\n\n\n\n\n\n\nspider\n\n spider (df, id_column=None, title=None, max_values=None, padding=1.25,\n         global_scale=False, ax=None, sz=10)\n\n*Plot a spider chart based on the given dataframe.\nParameters: - df: pandas DataFrame The input dataframe containing the data to be plotted. - id_column: str, optional The column name to be used as the identifier for each data point. If not provided, the index of the dataframe will be used. - title: str, optional The title of the spider chart. - max_values: dict, optional A dictionary specifying the maximum values for each category. If not provided, the maximum values will be calculated based on the data. - padding: float, optional The padding factor to be applied when calculating the maximum values. Default is 1.25. - global_scale: bool or float, optional If False, each category will have its own maximum value. If True, a single maximum value will be used for all categories. If a float value is provided, it will be used as the maximum value for all categories. - ax: matplotlib Axes, optional The axes on which to plot the spider chart. If not provided, a new figure and axes will be created. - sz: float, optional The size of the figure (both width and height) in inches. Default is 10.\nReturns: - None\nExample usage: spider(df, id_column=‘model’, title=‘Spider Chart’, max_values={‘category1’: 10, ‘category2’: 20}, padding=1.5)*\n\nimport pandas as pd\n\nspider(\n    pd.DataFrame(\n        {\n            \"x\": [*\"abcde\"],\n            \"c1\": [10, 11, 12, 13, 14],\n            \"c2\": [0.1, 0.3, 0.4, 0.1, 0.9],\n            \"c3\": [1e5, 2e5, 3.5e5, 8e4, 5e4],\n            \"c4\": [9, 12, 5, 2, 0.2],\n            \"test\": [1, 1, 1, 1, 5],\n        },\n        index=[*\"abcde\"],\n    ),\n    title=\"Sample Spider\",\n    padding=1.1,\n)\n\n\n\n\n\n\n\n\n\n\n\nUpSetAltair\n\n UpSetAltair (data=None, title='', subtitle='', sets=None, abbre=None,\n              sort_by='frequency', sort_order='ascending', width=1200,\n              height=700, height_ratio=0.6,\n              horizontal_bar_chart_width=300, color_range=['#55A8DB',\n              '#3070B5', '#30363F', '#F1AD60', '#DF6234', '#BDC6CA'],\n              highlight_color='#EA4667', glyph_size=200,\n              set_label_bg_size=1000, line_connection_size=2,\n              horizontal_bar_size=20, vertical_bar_label_size=16,\n              vertical_bar_padding=20)\n\n*This function generates Altair-based interactive UpSet plots.\nParameters: - data (pandas.DataFrame): Tabular data containing the membership of each element (row) in exclusive intersecting sets (column). - sets (list): List of set names of interest to show in the UpSet plots. This list reflects the order of sets to be shown in the plots as well. - abbre (list): Abbreviated set names. - sort_by (str): “frequency” or “degree” - sort_order (str): “ascending” or “descending” - width (int): Vertical size of the UpSet plot. - height (int): Horizontal size of the UpSet plot. - height_ratio (float): Ratio of height between upper and under views, ranges from 0 to 1. - horizontal_bar_chart_width (int): Width of horizontal bar chart on the bottom-right. - color_range (list): Color to encode sets. - highlight_color (str): Color to encode intersecting sets upon mouse hover. - glyph_size (int): Size of UpSet glyph (⬤). - set_label_bg_size (int): Size of label background in the horizontal bar chart. - line_connection_size (int): width of lines in matrix view. - horizontal_bar_size (int): Height of bars in the horizontal bar chart. - vertical_bar_label_size (int): Font size of texts in the vertical bar chart on the top. - vertical_bar_padding (int): Gap between a pair of bars in the vertical bar charts.*\n\n\n\nupsetaltair_top_level_configuration\n\n upsetaltair_top_level_configuration (base, legend_orient='top-left',\n                                      legend_symbol_size=30)\n\n*Configure the top-level settings for an UpSet plot in Altair.\nParameters: - base: The base chart to configure. - legend_orient: The orientation of the legend. Default is “top-left”. - legend_symbol_size: The size of the legend symbols. Default is 30.\nReturns: - The configured chart.*\n\ndf\n\n\n\n\n\n\n\n\ntruth\npred\n\n\n\n\n0\nc\nd\n\n\n1\nc\nc\n\n\n2\nd\nd\n\n\n3\nc\na\n\n\n4\nd\nc\n\n\n...\n...\n...\n\n\n995\nc\nc\n\n\n996\na\nc\n\n\n997\nb\na\n\n\n998\nb\nc\n\n\n999\na\nd\n\n\n\n\n1000 rows × 2 columns\n\n\n\n\n# import numpy as np\n\n# i = np.random.randn(300, 7) &gt; 0.33\n# df = pd.DataFrame(i.astype(int))\n# df.columns = [rand() for _ in range(len(df.columns))]\n# show(df)\n\n# UpSetAltair(\n#     df,\n#     sets=list(df.columns),\n#     abbre=list(df.columns),\n#     sort_by=\"frequencey\",\n#     sort_order=\"ascending\",\n# )\n\n\n\n\nERROR:root:No traceback has been produced, nothing to debug.",
    "crumbs": [
      "Altair and Other Charts"
    ]
  },
  {
    "objectID": "jupyter_notebook.html",
    "href": "jupyter_notebook.html",
    "title": "Jupyter Notebooks",
    "section": "",
    "text": "backup_folders_of_nbs\n\n backup_folders_of_nbs (src, dest)\n\n\n\n\nbackup_all_notebooks\n\n backup_all_notebooks (folder)\n\n\n\n\nbackup_this_notebook\n\n backup_this_notebook (this_file_path, save_html_to_dir=None,\n                       override_previous_backup=False, changelog=None,\n                       exclude_input=False, force_save_notebook=True)\n\n\n\n\nsave_notebook\n\n save_notebook (file_path)\n\n\nbackup_this_notebook(\"jupyter_notebook.ipynb\")\n\n\n\n\nshow_big_dataframe\n\n show_big_dataframe (df, max_rows=30)\n\n\n\n\ndisplay_dfs_side_by_side\n\n display_dfs_side_by_side (*args, titles=&lt;itertools.cycle object at\n                           0x13fd9b3c0&gt;, max_rows=50)\n\n\n\n\nh6\n\n h6 (text)\n\n\n\n\nh5\n\n h5 (text)\n\n\n\n\nh4\n\n h4 (text)\n\n\n\n\nh3\n\n h3 (text)\n\n\n\n\nh2\n\n h2 (text)\n\n\n\n\nh1\n\n h1 (text)\n\n\n\n\nstore_scrap\n\n store_scrap (at)\n\n\n\n\nshutdown_current_notebook\n\n shutdown_current_notebook (delay:int=None)",
    "crumbs": [
      "Jupyter Notebooks"
    ]
  },
  {
    "objectID": "misc.html",
    "href": "misc.html",
    "title": "Miscellaneous",
    "section": "",
    "text": "l = list(range(10, 0, -1))\nfact = 10\nt = sum(l) / fact\nfor i in track2(l):\n    time.sleep(i / fact)\n    print()\n\n\n1/10 (1.01s - 9.05s remaining - 1.01 s/iter)          \n2/10 (1.91s - 7.63s remaining - 1.05 iters/s)          \n3/10 (2.71s - 6.33s remaining - 1.11 iters/s)          \n4/10 (3.42s - 5.12s remaining - 1.17 iters/s)          \n5/10 (4.02s - 4.02s remaining - 1.24 iters/s)          \n6/10 (4.52s - 3.01s remaining - 1.33 iters/s)          \n7/10 (4.92s - 2.11s remaining - 1.42 iters/s)          \n8/10 (5.23s - 1.31s remaining - 1.53 iters/s)          \n9/10 (5.43s - 0.60s remaining - 1.66 iters/s)          \n10/10 (5.53s - 0.00s remaining - 1.81 iters/s)\nUse timer as a standalone class so you have full control on when to call a lap (most useful in while loops)…\nN = 100\nt = Timer(N)\ninfo = None\n\nfor i in range(N):\n    time.sleep(0.1)\n    t(info=info)  # Lap and present the time\n    if i == 50:\n        print()\n        info = f\"My Info: {i*3.122}\"\n\n51/100 (5.28s - 5.07s remaining - 9.66 iters/s)          \nMy Info: 156.1  100/100 (10.38s - 0.00s remaining - 9.63 iters/s)\n… or use track2 to directly track a loop\nN = 100\ninfo = None\n\nfor i in (tracker := track2(range(N), total=N)):\n    time.sleep(0.1)\n    info = f\"My Info: {i*3.122:.2f}\"\n    if i == N // 2:\n        print()\n    if i &gt;= N // 2:\n        tracker.send(info)\n\n50/100 (5.20s - 5.20s remaining - 9.61 iters/s)          \nMy Info: 309.08 100/100 (10.36s - 0.00s remaining - 9.65 iters/s)",
    "crumbs": [
      "Miscellaneous"
    ]
  },
  {
    "objectID": "misc.html#warning-never-run-tracker.sendnone-as-this-will-skip-variables-silently",
    "href": "misc.html#warning-never-run-tracker.sendnone-as-this-will-skip-variables-silently",
    "title": "Miscellaneous",
    "section": "Warning! NEVER RUN tracker.send(None) as this will skip variables silently",
    "text": "Warning! NEVER RUN tracker.send(None) as this will skip variables silently\n\n@io\n@timeit\ndef foo(a, b=None):\n    if b is None:\n        return a + 1\n    else:\n        time.sleep(2)\n        return a + b\n\n\nwith debug_mode():\n    foo(10)\n    foo(10, b=20)\n\n[08/23/24 17:39:53] DEBUG    0.00 seconds to execute `foo`                                                                                            1296653500.py:inner:16\n\n\n\n                    DEBUG                                                                                                                          2064456364.py:&lt;module&gt;:12\n                             0.00 seconds to execute `inner`                                                                                                                \n                             args()                                                                                                                                         \n                               0 - 10 (🏷️ int)                                                                                                                               \n                             kwargs                                                                                                                                         \n                             outputs - 11 (🏷️ int)                                                                                                                           \n                                                                                                                                                                            \n                                                                                                                                                                            \n\n\n\n[08/23/24 17:39:55] DEBUG    2.01 seconds to execute `foo`                                                                                            1296653500.py:inner:16\n\n\n\n                    DEBUG                                                                                                                          2064456364.py:&lt;module&gt;:13\n                             2.01 seconds to execute `inner`                                                                                                                \n                             args()                                                                                                                                         \n                               0 - 10 (🏷️ int)                                                                                                                               \n                             kwargs                                                                                                                                         \n                               b - 20 (🏷️ int)                                                                                                                               \n                             outputs - 30 (🏷️ int)",
    "crumbs": [
      "Miscellaneous"
    ]
  },
  {
    "objectID": "misc.html#try-catch-with-a-single-line",
    "href": "misc.html#try-catch-with-a-single-line",
    "title": "Miscellaneous",
    "section": "Try Catch with a single line",
    "text": "Try Catch with a single line\n\n@tryy\ndef do(a, b, c):\n    return 1 / 0\n\n\nx = do(1, 2, c=10)\nassert x is None  # tryy returns None by default\n\n[08/23/24 17:48:03] ERROR    Error for `do` with                                                                                                      1057038067.py:inner:30\n                             args()                                                                                                                                         \n                               0 - 1 (🏷️ int)                                                                                                                                \n                               1 - 2 (🏷️ int)                                                                                                                                \n                             kwargs                                                                                                                                         \n                               c - 10 (🏷️ int)                                                                                                                               \n                                                                                                                                                                            \n                             ZeroDivisionError: division by zero                                                                                                            \n\n\n\nUse your own default on failure\n\n@tryy(output_to_return_on_fail=\"😔\")\ndef do(a, b, c):\n    return 1 / 0\n\n\ndo(1, 2, c=10)\n\n[08/23/24 17:48:04] ERROR    Error for `do` with                                                                                                      1057038067.py:inner:30\n                             args()                                                                                                                                         \n                               0 - 1 (🏷️ int)                                                                                                                                \n                               1 - 2 (🏷️ int)                                                                                                                                \n                             kwargs                                                                                                                                         \n                               c - 10 (🏷️ int)                                                                                                                               \n                                                                                                                                                                            \n                             ZeroDivisionError: division by zero                                                                                                            \n\n\n\n'😔'\n\n\nOptionally print the full stacktrace if needed\n\n@tryy(print_traceback=True, output_to_return_on_fail=\"😔\")\ndef do(a, b, c):\n    return 1 / 0\n\n\ndo(1, 2, c=10)\n\n[08/23/24 17:48:06] ERROR    Error for `do` with                                                                                                      1057038067.py:inner:30\n                             args()                                                                                                                                         \n                               0 - 1 (🏷️ int)                                                                                                                                \n                               1 - 2 (🏷️ int)                                                                                                                                \n                             kwargs                                                                                                                                         \n                               c - 10 (🏷️ int)                                                                                                                               \n                                                                                                                                                                            \n                             Traceback (most recent call last):                                                                                                             \n                               File \"/var/folders/1_/71dqv9vx2750gmyz77q_f45w0000gn/T/ipykernel_28490/1057038067.py\", line 21, in inner                                     \n                                 return f(*args, **kwargs)                                                                                                                  \n                                        ^^^^^^^^^^^^^^^^^^                                                                                                                  \n                               File \"/var/folders/1_/71dqv9vx2750gmyz77q_f45w0000gn/T/ipykernel_28490/580638143.py\", line 3, in do                                          \n                                 return 1 / 0                                                                                                                               \n                                        ~~^~~                                                                                                                               \n                             ZeroDivisionError: division by zero                                                                                                            \n                                                                                                                                                                            \n\n\n\n'😔'\n\n\nYou can also silence the errors completely\n\n@tryy(silence_errors=True, output_to_return_on_fail=\"😔\")\ndef do(a, b, c):\n    return 1 / 0\n\n\ndo(1, 2, c=10)\n\n'😔'\n\n\nYou can collect all your errors in a list\n\nimport random\n\nerrors = []\n\n\n@tryy(silence_errors=True, store_errors=errors)\ndef do(a, b, c):\n    if random.randint(0, 100) &lt; 50:\n        return 1 / 0\n    else:\n        raise NotImplementedError(\"🤔\")\n\n\nfor _ in range(4):\n    do(1, random.randint(0, 10), c=random.randint(0, 100))\n\nprint(errors)\n\n[\n```↯ AttrDict ↯\nfunc - do (🏷️ str)\nargs()\n  0 - 1 (🏷️ int)\n  1 - 6 (🏷️ int)\nkwargs\n  c - 51 (🏷️ int)\ntb - ZeroDivisionError: division by zero (🏷️ str)\nerr_type - ZeroDivisionError (🏷️ str)\n\n```\n, \n```↯ AttrDict ↯\nfunc - do (🏷️ str)\nargs()\n  0 - 1 (🏷️ int)\n  1 - 6 (🏷️ int)\nkwargs\n  c - 35 (🏷️ int)\ntb - NotImplementedError: 🤔 (🏷️ str)\nerr_type - NotImplementedError (🏷️ str)\n\n```\n, \n```↯ AttrDict ↯\nfunc - do (🏷️ str)\nargs()\n  0 - 1 (🏷️ int)\n  1 - 1 (🏷️ int)\nkwargs\n  c - 3 (🏷️ int)\ntb - ZeroDivisionError: division by zero (🏷️ str)\nerr_type - ZeroDivisionError (🏷️ str)\n\n```\n, \n```↯ AttrDict ↯\nfunc - do (🏷️ str)\nargs()\n  0 - 1 (🏷️ int)\n  1 - 8 (🏷️ int)\nkwargs\n  c - 76 (🏷️ int)\ntb - ZeroDivisionError: division by zero (🏷️ str)\nerr_type - ZeroDivisionError (🏷️ str)\n\n```\n]\n\n\nThere’s onlly one usecase where you would want to send in a list by yourself - when you want to append your errors to an existing list. The sensible default is to always store the errors, especially because this is a debugging tool.\nJust access all the errors in a dataframe like so\n\nimport random\n\nrandom.seed(10)\nerrors = []\n\n\n@tryy(silence_errors=True, store_errors=errors, output_to_return_on_fail=\"😔\")\ndef do(a, b, c):\n    if c &lt; 50:\n        return 1 / 0\n    else:\n        raise NotImplementedError(\"🤔\")\n\n\nfor _ in range(4):\n    do(1, random.randint(0, 10), c=random.randint(0, 100))\n\ndo.error_summary()\n\n\n\n\n\n\n\n\nfunc\nargs\nkwargs\ntb\nerr_type\n\n\n\n\n0\ndo\n[1, 9]\n{'c': 4}\nZeroDivisionError: division by zero\nZeroDivisionError\n\n\n1\ndo\n[1, 6]\n{'c': 61}\nNotImplementedError: 🤔\nNotImplementedError\n\n\n2\ndo\n[1, 9]\n{'c': 1}\nZeroDivisionError: division by zero\nZeroDivisionError\n\n\n3\ndo\n[1, 3]\n{'c': 59}\nNotImplementedError: 🤔\nNotImplementedError\n\n\n\n\n\n\n\nand the actual list of errors like so\n\ndo.error_store\n\n[\n ```↯ AttrDict ↯\n func - do (🏷️ str)\n args()\n   0 - 1 (🏷️ int)\n   1 - 9 (🏷️ int)\n kwargs\n   c - 4 (🏷️ int)\n tb - ZeroDivisionError: division by zero (🏷️ str)\n err_type - ZeroDivisionError (🏷️ str)\n \n ```,\n \n ```↯ AttrDict ↯\n func - do (🏷️ str)\n args()\n   0 - 1 (🏷️ int)\n   1 - 6 (🏷️ int)\n kwargs\n   c - 61 (🏷️ int)\n tb - NotImplementedError: 🤔 (🏷️ str)\n err_type - NotImplementedError (🏷️ str)\n \n ```,\n \n ```↯ AttrDict ↯\n func - do (🏷️ str)\n args()\n   0 - 1 (🏷️ int)\n   1 - 9 (🏷️ int)\n kwargs\n   c - 1 (🏷️ int)\n tb - ZeroDivisionError: division by zero (🏷️ str)\n err_type - ZeroDivisionError (🏷️ str)\n \n ```,\n \n ```↯ AttrDict ↯\n func - do (🏷️ str)\n args()\n   0 - 1 (🏷️ int)\n   1 - 3 (🏷️ int)\n kwargs\n   c - 59 (🏷️ int)\n tb - NotImplementedError: 🤔 (🏷️ str)\n err_type - NotImplementedError (🏷️ str)\n \n ```]\n\n\nFinally, you want to run the function (without try) to reproduce the error and actually start debugging. Just use the .F attribute to access the original function that you created\n\nix = 2\ndata = do.error_store[ix]\ndo.F(*data.args, **data.kwargs)\n\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nCell In[51], line 3\n      1 ix = 2\n      2 data = do.error_store[ix]\n----&gt; 3 do.F(*data.args, **data.kwargs)\n\nCell In[49], line 9, in do(a, b, c)\n      6 @tryy(silence_errors=True, store_errors=errors, output_to_return_on_fail=\"😔\")\n      7 def do(a, b, c):\n      8     if c &lt; 50:\n----&gt; 9         return 1 / 0\n     10     else:\n     11         raise NotImplementedError(\"🤔\")\n\nZeroDivisionError: division by zero\n\n\n\n\ndef deco(decorator):\n    @wraps(decorator)\n    def wrapper(*args, **kwargs):\n        def real_decorator(func):\n            @wraps(func)\n            def inner_wrapper(*fargs, **fkwargs):\n                return decorator(func, *fargs, **fkwargs)\n\n            return inner_wrapper\n\n        if len(args) == 1 and callable(args[0]) and not kwargs:\n            # Case when B is used without arguments\n            return real_decorator(args[0])\n        else:\n            # Case when B is used with arguments\n            def custom_decorator(func):\n                return decorator(func, **kwargs)\n\n            return custom_decorator\n\n    return wrapper\n\n\n@deco\ndef B(func, *args, deco_param=\"default\", **kwargs):\n    print(\"B\", deco_param, print(\"args\", *args, \"kwargs\", **kwargs))\n    return func(*args, **kwargs)\n\n\n@B\ndef C(a, b, c):\n    print(\"C\")\n    return a + (b * c)\n\n\nC(1, 2, 3)\n\nargs 1 2 3 kwargs\nB default None\nC\n\n\n7\n\n\n\n@B(deco_param=\"new_param\")\ndef C(a, b, c):\n    return a + (b * c)\n\n\n# Testing\nprint(C(1, 2, 3))  # Outputs 'new_param' then the result 7\n\nargs kwargs\nB new_param None\n\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[16], line 1\n----&gt; 1 @B(deco_param=\"new_param\")\n      2 def C(a, b, c):\n      3     return a + (b * c)\n      6 # Testing\n\nCell In[13], line 17, in deco.&lt;locals&gt;.wrapper.&lt;locals&gt;.custom_decorator(func)\n     16 def custom_decorator(func):\n---&gt; 17     return decorator(func, **kwargs)\n\nCell In[14], line 4, in B(func, deco_param, *args, **kwargs)\n      1 @deco\n      2 def B(func, *args, deco_param=\"default\", **kwargs):\n      3     print(\"B\", deco_param, print(\"args\", *args, \"kwargs\", **kwargs))\n----&gt; 4     return func(*args, **kwargs)\n\nTypeError: C() missing 3 required positional arguments: 'a', 'b', and 'c'",
    "crumbs": [
      "Miscellaneous"
    ]
  },
  {
    "objectID": "adapters.html",
    "href": "adapters.html",
    "title": "Adapters",
    "section": "",
    "text": "Adapters\nTo convert data from/to various formats\n\n\n\nfile_2_bytes\n\n file_2_bytes (fpath)\n\n\n\n\nbytes_2_file\n\n bytes_2_file (input:bytes, fpath:Union[str,pathlib.Path],\n               silent:bool=False)\n\nSave bytes input at given fpath\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput\nbytes\n\nbytes\n\n\nfpath\nUnion\n\nPlace where you want to save the file\n\n\nsilent\nbool\nFalse\n\n\n\nReturns\nNone\n\n\n\n\n\n\n\n\nb64_2_file\n\n b64_2_file (input:str, fpath:Union[str,pathlib.Path])\n\nSave a file encoded as a base64 input at given fpath\n\n\n\n\nType\nDetails\n\n\n\n\ninput\nstr\nbase64 encoded string\n\n\nfpath\nUnion\nPlace where you want to save the file\n\n\nReturns\nNone\n\n\n\n\n\n\n\nb64_2_np\n\n b64_2_np (input:str)\n\n*Converts a base64 encoded image to a NumPy array.\nArgs: input (str): The base64 encoded image.\nReturns: np.ndarray: The NumPy array representation of the image in RGB format.*\n\n\n\nnp_2_b64\n\n np_2_b64 (image:numpy.ndarray)\n\nConvert a numpy image to base64 string\n\n\n\ncvat_2_csvs\n\n cvat_2_csvs (xmlfile, csvs_folder)\n\n*Convert CVAT XML annotations to CSV files.\nArgs: xmlfile (str): Path to the CVAT XML file. csvs_folder (str): Path to the folder where the CSV files will be saved.\nReturns: None*\n\n\n\ncsvs_2_cvat\n\n csvs_2_cvat (images_folder, csvs_folder, xml_output_file, items=None,\n              parquet=False, relative_df=True, default_label='Background',\n              extension='jpg')\n\n*Convert CSV annotations to CVAT XML format.\nArgs: images_folder (str): Path to the folder containing the images. csvs_folder (str): Path to the folder containing the CSV annotations. xml_output_file (str): Path to the output XML file. items (list, optional): List of items to process. If None, all items will be processed. Defaults to None. parquet (bool, optional): Whether the annotations are stored in Parquet format. Defaults to False. relative_df (bool, optional): Whether the bounding box coordinates in the CSV are relative to the image size. Defaults to True. default_label (str, optional): Default label for the bounding boxes. Defaults to “Background”. extension (str, optional): Image file extension. Defaults to “jpg”.\nReturns: None*",
    "crumbs": [
      "Adapters"
    ]
  },
  {
    "objectID": "capsule.html",
    "href": "capsule.html",
    "title": "Capsule (Tutorial)",
    "section": "",
    "text": "Let’s load the iris dataset first\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\ndata = load_iris()\nX, y = data.data, data.target\nX_trn, X_val, y_trn, y_val = train_test_split(X, y, random_state=42)\n\n… and create the data loaders\n\nfrom torch_snippets.inspector import inspect\nfrom torch.utils.data import TensorDataset\n\ntrn_ds = TensorDataset(*[torch.Tensor(i) for i in [X_trn, y_trn]])\ntrn_dl = DataLoader(trn_ds, batch_size=32)\n\nval_ds = TensorDataset(*[torch.Tensor(i) for i in [X_val, y_val]])\nval_dl = DataLoader(val_ds, batch_size=32)\n\ninspect(next(iter(val_dl)))\n\n══════════════════════════════════════════════════════════════════\nlist of 2 items\ntensor([[6.1000, 2.8000, 4.7000, 1.2000],\n        [5.7000, 3.8000, 1.7000, 0.3000],\n        [7.7000, 2.6000, 6.9000, 2.3000],\n        [6.0000, 2.9000, 4.5000, 1.5000],\n        [6.8000, 2.8000, 4.8000, 1.4000],\n        [5.4000, 3.4000, 1.5000, 0.4000],\n        [5.6000, 2.9000, 3.6000, 1.3000],\n        [6.9000, 3.1000, 5.1000, 2.3000],\n        [6.2000, 2.2000, 4.5000, 1.5000],\n        [5.8000, 2.7000, 3.9000, 1.2000],\n        [6.5000, 3.2000, 5.1000, 2.0000],\n        [4.8000, 3.0000, 1.4000, 0.1000],\n        [5.5000, 3.5000, 1.3000, 0.2000],\n        [4.9000, 3.1000, 1.5000, 0.1000],\n        [5.1000, 3.8000, 1.5000, 0.3000],\n        [6.3000, 3.3000, 4.7000, 1.6000],\n        [6.5000, 3.0000, 5.8000, 2.2000],\n        [5.6000, 2.5000, 3.9000, 1.1000],\n        [5.7000, 2.8000, 4.5000, 1.3000],\n        [6.4000, 2.8000, 5.6000, 2.2000],\n        [4.7000, 3.2000, 1.6000, 0.2000],\n        [6.1000, 3.0000, 4.9000, 1.8000],\n        [5.0000, 3.4000, 1.6000, 0.4000],\n        [6.4000, 2.8000, 5.6000, 2.1000],\n        [7.9000, 3.8000, 6.4000, 2.0000],\n        [6.7000, 3.0000, 5.2000, 2.3000],\n        [6.7000, 2.5000, 5.8000, 1.8000],\n        [6.8000, 3.2000, 5.9000, 2.3000],\n        [4.8000, 3.0000, 1.4000, 0.3000],\n        [4.8000, 3.1000, 1.6000, 0.2000],\n        [4.6000, 3.6000, 1.0000, 0.2000],\n        [5.7000, 4.4000, 1.5000, 0.4000]])\ntensor([1., 0., 2., 1., 1., 0., 1., 2., 1., 1., 2., 0., 0., 0., 0., 1., 2., 1.,\n        1., 2., 0., 2., 0., 2., 2., 2., 2., 2., 0., 0., 0., 0.])\n══════════════════════════════════════════════════════════════════\n\n\nNext we’ll import Capsule and a few decorators that will tell the model to change it’s mode to train/test during the fit function\nfrom torch_snippets.trainer.capsule import Capsule, train, validate, predict\nCreate the neural network and define it’s forward function as usual pytorch business. Only difference now is that you’ll also add self.loss_fn and self.optimizer attributes in the init\nclass IrisModel(Capsule):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.BatchNorm1d(4),\n            nn.Linear(4, 16),\n            nn.Dropout(0.2),\n            nn.BatchNorm1d(16),\n            nn.ReLU(inplace=True),\n            nn.Linear(16, 8),\n            nn.Dropout(0.2),\n            nn.BatchNorm1d(8),\n            nn.ReLU(inplace=True),\n            nn.Linear(8, 3),\n        )\n        self.loss_fn = nn.CrossEntropyLoss()\n        self.optimizer = optim.Adam(self.parameters())\n\n    def forward(self, x):\n        return self.model(x)\nTo fully describe the model’s behaviour we still need to define three functions\n1. train_batch\n2. validate_batch and,\n3. predict which is optional\nlike so\n\n    @train\n    def train_batch(self, batch):\n        x, y = batch\n        _y = self.forward(x)\n        loss = self.loss_fn(_y, y.long())\n        return {\"loss\": loss}\n\n    @validate\n    def validate_batch(self, batch=None, dl=None):\n        if dl is not None:\n            output = []\n            for batch in dl:\n                output.extend(self.predict(batch=batch)[\"val_acc\"])\n            return np.mean(output)\n        x, y = batch\n        _y = self.forward(x)\n        loss = self.loss_fn(_y, y.long())\n        acc = (y == _y.max(-1)[1]).float().mean()\n        return {\"val_loss\": loss, \"val_acc\": acc}\n\n    @predict\n    def predict(self, batch=None, dl=None):\n        if dl is not None:\n            output = []\n            for batch in dl:\n                output.extend(self.predict(batch=batch))\n            return output\n        x, y = batch\n        _y = self.forward(x)\n        o = _y.max(-1)[1].cpu().detach().numpy().tolist()\n        return o\n\nEnsure you return dictionaries of losses, accuracy metrics in train_batch and validate_batch functions. You can return as many metrics during training and validation, they will be auto logged.\n\nAlso make sure at least one of the keys in train_batch is the key loss, as this is used to compute gradients.*\n\nWe could now create the model…\n\nmodel = IrisModel()\nmodel.device = \"cpu\"\n\n… and run model.fit with an optional number of logs to print to the console\n\nmodel.fit(trn_dl, val_dl, num_epochs=100, print_total=2, device=\"cpu\")\n\nEPOCH: 1.000    loss: 1.351 val_loss: 1.403 val_acc: 0.344  (0.69s - 67.83s remaining)\nEPOCH: 50.000   loss: 0.608 val_loss: 0.524 val_acc: 1.000  (2.86s - 2.86s remaining)\nEPOCH: 100.000  loss: 0.265 val_loss: 0.174 val_acc: 1.000  (3.28s - 0.00s remaining)\n\n\n\n\n\n\n\n\n\nmodel.evaluate accepts a validation data loader that will repeatedly call validate_batch and return aggregated metrics\n\nmodel.evaluate(val_dl, device=\"cpu\")\n\nEPOCH: 1.000    val_loss: 0.177 val_acc: 1.000  (0.01s - 0.00s remaining)\n\n\n{'val_loss': 0.1768618, 'val_acc': 1.0}",
    "crumbs": [
      "Capsule (Tutorial)"
    ]
  },
  {
    "objectID": "inspector.html",
    "href": "inspector.html",
    "title": "Inspect",
    "section": "",
    "text": "import torch, numpy as np\nfrom torch_snippets import inspect\n\ninspect(torch.randint(0, 100, size=(4, 3, 5)), np.random.randint(-10, 10, (9, 19, 1)))\n\n══════════════════════════════════════════════════════════════════\n\n\n\nTensor  Shape: torch.Size([4, 3, 5])    Min: 2.000      Max: 97.000     Mean: 46.317    dtype: torch.int64 @ cpu\n\n\n\n══════════════════════════════════════════════════════════════════\n\n\n\nndarray Shape: (9, 19, 1)       Min: -10.000    Max: 9.000      Mean: -0.345    dtype: int64\n\n\n\n══════════════════════════════════════════════════════════════════\n\n\n\n\nx = {\n    \"a\": [0, 1, 2, 3],\n    \"b\": torch.rand(10, 10),\n    \"c\": {\n        \"d\": np.arange(10),\n        \"e\": [\n            \"np.arange\",\n            {},\n            tuple(\n                [\n                    1,\n                    2,\n                ]\n            ),\n            set([1, 2, 3]),\n            [],\n            [11, 10],\n        ],\n    },\n}\ninspect(x)\n\n══════════════════════════════════════════════════════════════════\n\n\n\ndict of 3 items\n\n\n\n        A:\n        list of 4 items\n\n\n\n                int: 0\n\n\n\n                int: 1\n\n\n\n                int: 2\n\n\n\n                int: 3\n\n\n\n        B:\n        Tensor  Shape: torch.Size([10, 10])     Min: 0.000      Max: 0.989      Mean: 0.463     dtype: \ntorch.float32 @ cpu\n\n\n\n        C:\n        dict of 2 items\n\n\n\n                D:\n                ndarray Shape: (10,)    Min: 0.000      Max: 9.000      Mean: 4.500     dtype: int64\n\n\n\n                E:\n                list of 6 items\n\n\n\n                        str `np.arange`\n\n\n\n                        dict of 0 items\n\n\n\n                        tuple of 2 items\n\n\n\n                                int: 1\n\n\n\n                                int: 2\n\n\n\n                        set Length: 3\n\n\n\n                        list of 0 items\n\n\n\n                        and ... ... 1 more item(s)\n\n\n\n══════════════════════════════════════════════════════════════════",
    "crumbs": [
      "Inspect"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Utilities for simple needs",
    "section": "",
    "text": "Whether it is numpy, pandas, matplotlib or the useful functions that are mentioned below Simply call\nfrom torch_snippets import *\nAll the imports are lightweight and thus should not take more than a couple of seconds",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#torch-snippets-does-a-lot-of-default-importing-for-you",
    "href": "index.html#torch-snippets-does-a-lot-of-default-importing-for-you",
    "title": "Utilities for simple needs",
    "section": "",
    "text": "Whether it is numpy, pandas, matplotlib or the useful functions that are mentioned below Simply call\nfrom torch_snippets import *\nAll the imports are lightweight and thus should not take more than a couple of seconds",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#auxiliary-functions",
    "href": "index.html#auxiliary-functions",
    "title": "Utilities for simple needs",
    "section": "Auxiliary Functions",
    "text": "Auxiliary Functions\nThere are simple functions that are overloaded to take inputs and perform repetitive tasks that usually take a few lines to write\n\nImages\nshow, inspect, Glob, read, resize, rotate\n\n\nFiles and Paths\nstem, Glob, parent, name, fname,\nmakedir, zip_files, unzip_file,\nfind, extn,\nreadlines, writelines\n\n\nLists\nL, flatten\n\n\nDump and load python objects\nloaddill,dumpdill\n\n\nMisc\nTqdm, Timer, randint, Logger\n\n\nSets\nunique, diff, choose, common\n\n\nPytorch Modules\nReshape and Permute (nn.Modules)\n\n\nReport as Pytorch Lightning Callback\nLightningReport\n\n\nCharts\nChart from altair\nand many more to come…",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Utilities for simple needs",
    "section": "Install",
    "text": "Install\npip install torch_snippets",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "Utilities for simple needs",
    "section": "Usage",
    "text": "Usage\n\n\n\nCPU times: user 1.79 s, sys: 672 ms, total: 2.46 s\nWall time: 2.62 s\n\n\n\ndir()\n\n['AttrDict',\n 'B',\n 'BB',\n 'Blank',\n 'C',\n 'Chart',\n 'DataLoader',\n 'Dataset',\n 'Debug',\n 'E',\n 'Excep',\n 'F',\n 'Float',\n 'Glob',\n 'Image',\n 'ImportEnum',\n 'In',\n 'Inf',\n 'Info',\n 'Int',\n 'L',\n 'LightningReport',\n 'NullType',\n 'Out',\n 'P',\n 'PIL',\n 'Path',\n 'Permute',\n 'PrettyString',\n 'Report',\n 'Reshape',\n 'Self',\n 'ShowPrint',\n 'Stateful',\n 'Str',\n 'StrEnum',\n 'T',\n 'Timer',\n 'Tqdm',\n 'Warn',\n '_',\n '__',\n '___',\n '__builtin__',\n '__builtins__',\n '__doc__',\n '__loader__',\n '__name__',\n '__package__',\n '__spec__',\n '_dh',\n '_i',\n '_i1',\n '_i2',\n '_ih',\n '_ii',\n '_iii',\n '_oh',\n 'add',\n 'add_props',\n 'alt',\n 'anno_ret',\n 'annotations',\n 'arg0',\n 'arg1',\n 'arg2',\n 'arg3',\n 'arg4',\n 'argnames',\n 'argwhere',\n 'attrdict',\n 'basic_repr',\n 'bbfy',\n 'bind',\n 'camel2snake',\n 'charts',\n 'choose',\n 'chunked',\n 'class2attr',\n 'common',\n 'compose',\n 'copy_func',\n 'crop_from_bb',\n 'custom_dir',\n 'cv2',\n 'cycle',\n 'defaults',\n 'detuplify',\n 'device',\n 'df2bbs',\n 'diff',\n 'display',\n 'dumpdill',\n 'enlarge_bbs',\n 'eq',\n 'even_mults',\n 'exec_local',\n 'exit',\n 'extn',\n 'fastcores',\n 'fastuple',\n 'filter_dict',\n 'filter_ex',\n 'filter_keys',\n 'filter_values',\n 'find',\n 'first',\n 'flatten',\n 'fname',\n 'fname2',\n 'ge',\n 'gen',\n 'get_class',\n 'get_ipython',\n 'getattrs',\n 'glob',\n 'groupby',\n 'gt',\n 'hasattrs',\n 'ifnone',\n 'ignore_exceptions',\n 'in_',\n 'inspect',\n 'instantiate',\n 'inum_methods',\n 'is_',\n 'is_array',\n 'is_not',\n 'isdir',\n 'jitter',\n 'last_index',\n 'le',\n 'line',\n 'lines',\n 'listify',\n 'load_torch_model_weights_to',\n 'loaddill',\n 'loader',\n 'logger',\n 'lt',\n 'lzip',\n 'makedir',\n 'map_ex',\n 'maps',\n 'maybe_attr',\n 'md5',\n 'merge',\n 'mk_class',\n 'mul',\n 'ne',\n 'nested_attr',\n 'nested_idx',\n 'nn',\n 'not_',\n 'now',\n 'np',\n 'null',\n 'num_cpus',\n 'num_methods',\n 'nunique',\n 'optim',\n 'os',\n 'otherwise',\n 'pad',\n 'parent',\n 'partialler',\n 'patch',\n 'patch_property',\n 'patch_to',\n 'pd',\n 'pdb',\n 'pdfilter',\n 'pl',\n 'plt',\n 'properties',\n 'puttext',\n 'quit',\n 'rand',\n 'randint',\n 'range_of',\n 're',\n 'read',\n 'readPIL',\n 'readlines',\n 'rect',\n 'remove_duplicates',\n 'rename_batch',\n 'renumerate',\n 'replicate',\n 'resize',\n 'risinstance',\n 'rnum_methods',\n 'rotate',\n 'save_torch_model_weights_from',\n 'see',\n 'set_logging_level',\n 'setattrs',\n 'setify',\n 'show',\n 'shrink_bbs',\n 'snake2camel',\n 'sorted_ex',\n 'stem',\n 'stems',\n 'stop',\n 'store_attr',\n 'str_enum',\n 'sub',\n 'subplots',\n 'sys',\n 'th',\n 'to_absolute',\n 'to_relative',\n 'tonull',\n 'torch',\n 'torch_loader',\n 'torchvision',\n 'tqdm',\n 'trange',\n 'transforms',\n 'true',\n 'truediv',\n 'try_attrs',\n 'tuplify',\n 'type_hints',\n 'typed',\n 'uint',\n 'unique',\n 'uniqueify',\n 'unzip_file',\n 'using_attr',\n 'val2idx',\n 'with_cast',\n 'wrap_class',\n 'write',\n 'writelines',\n 'xywh2xyXY',\n 'zip_cycle',\n 'zip_files']",
    "crumbs": [
      "Utilities for simple needs"
    ]
  }
]