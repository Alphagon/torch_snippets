{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train PyTorch Keras style\n",
    "Taking full advantage of `Timer`, and other `torch_loader` utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp trainer.capsule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch_snippets.loader import *\n",
    "from torch_snippets.torch_loader import *\n",
    "from torch_snippets.paths import loaddill, dumpdill\n",
    "\n",
    "try:\n",
    "    import mmcv\n",
    "    from mmcv.parallel.data_container import DataContainer\n",
    "except ImportError:\n",
    "    DataContainer = None\n",
    "\n",
    "\n",
    "def to(item, device):\n",
    "    if item is None:\n",
    "        return None\n",
    "    elif isinstance(item, (torch.Tensor, nn.Module)):\n",
    "        return item.to(device)\n",
    "    elif isinstance(item, dict):\n",
    "        return {k: to(v, device) for k, v in item.items()}\n",
    "    elif isinstance(item, (list, tuple)):\n",
    "        return [to(_item, device) for _item in item]\n",
    "    elif DataContainer is not None and isinstance(item, DataContainer):\n",
    "        return [to(_item, device) for _item in item.data]\n",
    "    else:\n",
    "        # logger.warning(f\"function is not implemented for {type(item)}\")\n",
    "        return item\n",
    "        raise NotImplementedError(f\"function is not implemented for {type(item)}\")\n",
    "\n",
    "\n",
    "def train(train_function):\n",
    "    def _train_batch(self, *args, **kwargs):\n",
    "        args = self.before_train_batch(args)\n",
    "        kwargs = self.before_train_batch(kwargs)\n",
    "        outputs = train_function(self, *args, **kwargs)\n",
    "        outputs = self.after_train_batch(outputs)\n",
    "        assert isinstance(outputs, dict)\n",
    "        return outputs\n",
    "\n",
    "    return _train_batch\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(validation_function):\n",
    "    def _validate_batch(self, *args, **kwargs):\n",
    "        args = self.before_validate_batch(args)\n",
    "        kwargs = self.before_validate_batch(kwargs)\n",
    "        outputs = validation_function(self, *args, **kwargs)\n",
    "        outputs = self.after_validate_batch(outputs)\n",
    "        assert isinstance(outputs, dict)\n",
    "        return outputs\n",
    "\n",
    "    return _validate_batch\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(predict_function):\n",
    "    def _predict(self, *args, **kwargs):\n",
    "        args = self.before_predict(args)\n",
    "        kwargs = self.before_predict(kwargs)\n",
    "        outputs = predict_function(self, *args, **kwargs)\n",
    "        return outputs\n",
    "\n",
    "    return _predict\n",
    "\n",
    "\n",
    "class Capsule(nn.Module):\n",
    "    def __init__(self, report=None):\n",
    "        super().__init__()\n",
    "        if report is not None:\n",
    "            self.report = loaddill(report)\n",
    "\n",
    "    # Train Utils\n",
    "    def before_train_batch(self, data):\n",
    "        self.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        data = to(data, getattr(self, \"device\", \"cuda\"))\n",
    "        return data\n",
    "\n",
    "    def after_train_batch(self, outputs):\n",
    "        outputs[\"loss\"].backward()\n",
    "        self.optimizer.step()\n",
    "        return outputs\n",
    "\n",
    "    # Validation Utils\n",
    "    def before_validate_batch(self, data):\n",
    "        self.eval()\n",
    "        data = to(data, getattr(self, \"device\", \"cuda\"))\n",
    "        return data\n",
    "\n",
    "    def after_validate_batch(self, outputs):\n",
    "        return outputs\n",
    "\n",
    "    def before_predict(self, data):\n",
    "        self.eval()\n",
    "        data = to(data, getattr(self, \"device\", \"cuda\"))\n",
    "        return data\n",
    "\n",
    "    def after_predict(self, outputs):\n",
    "        return outputs\n",
    "\n",
    "    def load(self, weights_path=None, device=\"cpu\"):\n",
    "        if weights_path:\n",
    "            load_torch_model_weights_to(self, weights_path, device=device)\n",
    "        try:\n",
    "            weights_path = weights_path + \".report\"\n",
    "            self.report = loaddill(weights_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def save(self, save_to):\n",
    "        save_torch_model_weights_from(self, save_to)\n",
    "        save_to = save_to + \".report\"\n",
    "        dumpdill(self.report, save_to)\n",
    "\n",
    "    # Fit function\n",
    "    def fit(\n",
    "        self,\n",
    "        trn_dl=None,\n",
    "        val_dl=None,\n",
    "        num_epochs=1,\n",
    "        device=\"cuda\",\n",
    "        save_to=None,\n",
    "        print_every=None,\n",
    "        print_total=None,\n",
    "        show_final_plot=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if print_total:\n",
    "            print_every = num_epochs // print_total\n",
    "\n",
    "        if not hasattr(self, \"report\"):\n",
    "            self.report = Report(num_epochs, **kwargs)\n",
    "        else:\n",
    "            self.report = Report(num_epochs, old_report=self.report, **kwargs)\n",
    "\n",
    "        self.device = device\n",
    "        to(self, self.device)\n",
    "\n",
    "        try:\n",
    "            for epoch in range(num_epochs):\n",
    "                self.report.n_epochs = num_epochs\n",
    "                if trn_dl is not None:\n",
    "                    N = len(trn_dl)\n",
    "                    for ix, data in enumerate(trn_dl):\n",
    "                        loss = self.train_batch(data)\n",
    "                        self.report.record(pos=(epoch + (ix + 1) / N), **loss, end=\"\\r\")\n",
    "                if val_dl is not None:\n",
    "                    self.evaluate(\n",
    "                        val_dl, report=self.report, device=device, epoch=epoch\n",
    "                    )\n",
    "                if (print_every and ((epoch + 1) % print_every == 0)) or epoch == 0:\n",
    "                    self.report.report_avgs(epoch + 1)\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "\n",
    "        if show_final_plot:\n",
    "            self.report.plot(log=True, smooth=0)\n",
    "        if save_to:\n",
    "            self.save(save_to)\n",
    "\n",
    "    def evaluate(self, val_dl, report=None, device=\"cuda\", epoch=None):\n",
    "        if report is None:\n",
    "            show_report = True\n",
    "            report = Report(1)\n",
    "            epoch = 0\n",
    "        else:\n",
    "            show_report = False\n",
    "            epoch = epoch\n",
    "        self.device = device\n",
    "        to(self, self.device)\n",
    "\n",
    "        N = len(val_dl)\n",
    "        for ix, data in enumerate(val_dl):\n",
    "            loss = self.validate_batch(data)\n",
    "            report.record(pos=(epoch + (ix + 1) / N), **loss, end=\"\\r\")\n",
    "\n",
    "        if show_report:\n",
    "            report.report_avgs(1)\n",
    "            report.plot(log=True, smooth=3)\n",
    "\n",
    "    @train\n",
    "    def train_batch(self, data):\n",
    "        x, y = data\n",
    "        _y = self(x)\n",
    "        loss = self.criterion(_y, y)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @validate\n",
    "    def validate_batch(self, data):\n",
    "        x, y = data\n",
    "        output = self(x)\n",
    "        loss = self.criterion(output, y)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @predict\n",
    "    def predict_batch(self, data):\n",
    "        x, _ = data\n",
    "        outputs = self(x)\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
